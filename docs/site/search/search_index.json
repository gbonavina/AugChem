{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Augchem","text":"<p>Welcome to the documentation for Augchem, a Python toolbox for chemical data augmentation, developed in partnership with FAPESP and CINE.</p>"},{"location":"#overview","title":"Overview","text":"<p>Augchem provides comprehensive tools for chemical data augmentation across multiple molecular representations:</p> <ul> <li>\ud83d\udd24 SMILES: String-based molecular representation augmentation with advanced text manipulation</li> <li>\ud83d\udd17 Graphs: PyTorch Geometric-based molecular graph augmentation with structural modifications</li> <li>\ud83e\uddec InChI: International Chemical Identifier augmentation for standardized representations</li> </ul>"},{"location":"#features","title":"Features","text":""},{"location":"#smiles-augmentation","title":"\ud83d\udd24 SMILES Augmentation","text":"<ul> <li>Masking: Replace molecular tokens with mask symbols for robust training</li> <li>Deletion: Remove random tokens to create structural variations  </li> <li>Swapping: Exchange atom positions for diverse canonical forms</li> <li>Fusion: Combine multiple augmentation techniques intelligently</li> <li>Enumeration: Generate non-canonical SMILES representations</li> <li>Dataset Processing: Batch augmentation of molecular datasets with property preservation</li> <li>Quality Control: Built-in validation using RDKit for chemical correctness</li> </ul>"},{"location":"#graph-augmentation","title":"\ud83d\udd17 Graph Augmentation","text":"<ul> <li>Edge Dropping: Remove bidirectional edges to create structural variations</li> <li>Node Dropping: Remove nodes while maintaining graph integrity</li> <li>Feature Masking: Mask node features for robust representation learning</li> <li>Edge Perturbation: Add and remove edges to explore chemical space</li> <li>Batch Processing: Efficient processing using PyTorch Geometric DataLoaders</li> <li>Advanced Analytics: Comprehensive graph statistics and visualization tools</li> </ul>"},{"location":"#integration-compatibility","title":"\u26a1 Integration &amp; Compatibility","text":"<ul> <li>PyTorch Geometric: Native support for graph neural networks</li> <li>RDKit Integration: Chemical validation and property calculation</li> <li>Pandas Support: Seamless DataFrame processing for datasets</li> <li>Reproducible Results: Seed-based random state management</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#smiles-processing","title":"\ud83c\udfaf SMILES Processing","text":"<ul> <li>Token-Level Manipulation: Intelligent parsing and modification of SMILES strings</li> <li>Chemical Validity: Automatic validation to ensure augmented molecules remain valid</li> <li>Property Preservation: Maintain molecular properties during augmentation</li> <li>Flexible Parameters: Customizable masking, deletion, and fusion ratios</li> <li>Batch Operations: Process entire molecular datasets efficiently</li> </ul>"},{"location":"#graph-processing","title":"\ud83d\udd17 Graph Processing","text":"<ul> <li>Multi-Technique Augmentation: Combine edge, node, and feature modifications</li> <li>Self-Loop Detection: Automatic cleanup for graph neural network compatibility</li> <li>Batch Collation: Optimized for PyTorch Geometric DataLoaders</li> <li>Quality Metrics: Built-in graph validation and statistics</li> </ul>"},{"location":"#developer-experience","title":"\ud83d\udee0\ufe0f Developer Experience","text":"<ul> <li>Simple API: Intuitive interface for both beginners and experts</li> <li>Comprehensive Documentation: Detailed tutorials and examples</li> <li>Extensible Design: Easy to add custom augmentation techniques</li> <li>Production Ready: Tested and optimized for research and industry use</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#smiles-augmentation_1","title":"SMILES Augmentation","text":"<pre><code>from augchem import Augmentator\n\n# Initialize augmentator\naugmentator = Augmentator(seed=42)\n\n# Augment SMILES dataset\nresult = augmentator.SMILES.augment_data(\n    dataset=\"molecules.csv\",\n    augmentation_methods=[\"mask\", \"fusion\", \"enumeration\"],\n    augment_percentage=0.3,\n    col_to_augment=\"SMILES\"\n)\n</code></pre>"},{"location":"#graph-augmentation_1","title":"Graph Augmentation","text":"<pre><code>from augchem.modules.graph.graphs_modules import augment_dataset\n\n# Apply multiple augmentation techniques\naugmented_graphs = augment_dataset(\n    graphs=your_graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask'],\n    augment_percentage=0.2\n)\n</code></pre>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>Ready to enhance your molecular datasets? Choose your path:</p> <ul> <li>\ud83d\udcda Tutorials - Step-by-step learning guides</li> <li>\ud83d\udca1 Examples - Practical applications and use cases  </li> <li>\ud83d\udcd6 API Reference - Complete technical documentation</li> </ul> <p>Explore the comprehensive documentation to master both SMILES and graph augmentation techniques!</p>"},{"location":"examples/","title":"Examples","text":"<p>This section provides practical examples of using AugChem for molecular data augmentation. Choose the appropriate section based on your data type and augmentation needs.</p>"},{"location":"examples/#quick-overview","title":"\ud83e\uddea Quick Overview","text":"<p>AugChem supports two main types of molecular data augmentation:</p> <ul> <li>\ud83d\udd24 SMILES Augmentation: String-based molecular representation augmentation</li> <li>\ud83d\udd17 Graph Augmentation: Graph neural network-ready molecular graph augmentation</li> </ul>"},{"location":"examples/#available-example-collections","title":"\ud83d\udccb Available Example Collections","text":""},{"location":"examples/#smiles-examples","title":"SMILES Examples","text":"<p>Comprehensive examples for SMILES-based molecular augmentation including: - Basic SMILES manipulation techniques - Dataset-level augmentation strategies - Quality control and validation - Real-world drug discovery applications - Integration with cheminformatics workflows</p>"},{"location":"examples/#graph-examples","title":"Graph Examples","text":"<p>Detailed examples for graph-based molecular augmentation including: - PyTorch Geometric integration - Individual augmentation techniques - Machine learning pipeline integration - Comparative analysis and visualization - Advanced pharmaceutical applications</p>"},{"location":"examples/#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>If you're new to AugChem, we recommend:</p> <ol> <li>Start with Prerequisites: Install required packages</li> <li>Choose Your Data Type: SMILES strings or molecular graphs</li> <li>Follow Relevant Examples: Pick examples that match your use case</li> <li>Experiment: Modify parameters to suit your specific needs</li> </ol>"},{"location":"examples/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install augchem torch torch-geometric rdkit pandas matplotlib\n</code></pre>"},{"location":"examples/#basic-usage-pattern","title":"Basic Usage Pattern","text":"<pre><code>from augchem import Augmentator\n\n# Initialize with reproducible seed\naugmentator = Augmentator(seed=42)\n\n# For SMILES data\nsmiles_result = augmentator.SMILES.augment_data(\n    dataset=\"your_data.csv\",\n    augmentation_methods=[\"fusion\", \"enumeration\"],\n    augment_percentage=0.5\n)\n\n# For Graph data (when available)\n# graph_result = augmentator.Graph.augment_dataset(...)\n</code></pre>"},{"location":"examples/#example-categories","title":"\ud83c\udfaf Example Categories","text":""},{"location":"examples/#beginner-examples","title":"Beginner Examples","text":"<ul> <li>Basic augmentation setup</li> <li>Single molecule processing</li> <li>Simple dataset expansion</li> </ul>"},{"location":"examples/#intermediate-examples","title":"Intermediate Examples","text":"<ul> <li>Parameter optimization</li> <li>Quality control implementation</li> <li>Integration with ML pipelines</li> </ul>"},{"location":"examples/#advanced-examples","title":"Advanced Examples","text":"<ul> <li>Custom augmentation strategies</li> <li>Large-scale processing</li> <li>Research-grade applications</li> </ul>"},{"location":"examples/#tips-for-using-examples","title":"\ud83d\udca1 Tips for Using Examples","text":"<ol> <li>Modify Parameters: Adjust augmentation rates based on your data</li> <li>Validate Results: Always check output quality</li> <li>Set Seeds: Use random seeds for reproducible experiments</li> <li>Start Small: Test with small datasets first</li> <li>Monitor Performance: Track augmentation impact on model performance</li> </ol>"},{"location":"examples/#real-world-applications","title":"\ud83d\udd2c Real-World Applications","text":"<p>Our examples cover scenarios from: - Academic Research: Dataset expansion for publications - Drug Discovery: Virtual compound generation - Chemical Informatics: Property prediction enhancement - Materials Science: Novel structure exploration</p>"},{"location":"examples/#additional-resources","title":"\ud83d\udcd6 Additional Resources","text":"<ul> <li>SMILES Tutorial - Step-by-step learning guide</li> <li>Graph Tutorial - Comprehensive graph augmentation guide  </li> <li>API Reference - Complete function documentation</li> </ul> <p>Ready to augment your molecular data? Choose your examples and start exploring! \ud83e\uddec\u2728</p>"},{"location":"graph_examples/","title":"Graph Examples","text":"<p>This section provides practical examples of using AugChem for graph-based molecular data augmentation.</p>"},{"location":"graph_examples/#example-1-basic-graph-augmentation","title":"Example 1: Basic Graph Augmentation","text":"<pre><code>import torch\nfrom torch_geometric.data import Data\nfrom augchem.modules.graph.graphs_modules import augment_dataset\n\n# Create sample molecular graphs\ndef create_sample_graph(num_nodes, num_edges):\n    x = torch.randn(num_nodes, 9)  # 9 node features\n    edge_index = torch.randint(0, num_nodes, (2, num_edges))\n    edge_attr = torch.randn(num_edges, 4)  # 4 edge features\n    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n\n# Create a small dataset\ngraphs = [\n    create_sample_graph(10, 18),\n    create_sample_graph(12, 22),\n    create_sample_graph(8, 14),\n    create_sample_graph(15, 28)\n]\n\n# Apply augmentation\naugmented_graphs = augment_dataset(\n    graphs=graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask'],\n    edge_drop_rate=0.1,\n    node_drop_rate=0.05,\n    feature_mask_rate=0.15,\n    augment_percentage=0.5,  # 50% more data\n    seed=42\n)\n\nprint(f\"Dataset expanded from {len(graphs)} to {len(augmented_graphs)} graphs\")\n</code></pre>"},{"location":"graph_examples/#example-2-processing-real-molecular-data","title":"Example 2: Processing Real Molecular Data","text":"<pre><code>from rdkit import Chem\nimport torch\nfrom torch_geometric.data import Data\nfrom augchem.modules.graph.graphs_modules import augment_dataset\n\ndef smiles_to_graph(smiles):\n    \"\"\"Convert SMILES to PyTorch Geometric graph\"\"\"\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return None\n\n    # Node features\n    atom_features = []\n    for atom in mol.GetAtoms():\n        features = [\n            atom.GetAtomicNum(),\n            atom.GetDegree(),\n            atom.GetFormalCharge(),\n            int(atom.GetHybridization()),\n            int(atom.GetIsAromatic()),\n            atom.GetNumRadicalElectrons(),\n            atom.GetTotalNumHs(),\n            int(atom.IsInRing()),\n            atom.GetMass()\n        ]\n        atom_features.append(features)\n\n    # Edge features\n    edge_indices = []\n    edge_attrs = []\n    for bond in mol.GetBonds():\n        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n        edge_indices.extend([[i, j], [j, i]])  # Bidirectional\n\n        bond_features = [\n            bond.GetBondTypeAsDouble(),\n            int(bond.GetIsAromatic()),\n            int(bond.IsInRing()),\n            int(bond.GetIsConjugated())\n        ]\n        edge_attrs.extend([bond_features, bond_features])\n\n    return Data(\n        x=torch.tensor(atom_features, dtype=torch.float),\n        edge_index=torch.tensor(edge_indices, dtype=torch.long).t().contiguous(),\n        edge_attr=torch.tensor(edge_attrs, dtype=torch.float)\n    )\n\n# Example molecules\nmolecules = [\n    \"CCO\",  # Ethanol\n    \"CC(=O)O\",  # Acetic acid\n    \"c1ccccc1\",  # Benzene\n    \"CCN(CC)CC\",  # Triethylamine\n    \"CC(C)O\"  # Isopropanol\n]\n\n# Convert to graphs\ngraphs = [smiles_to_graph(smiles) for smiles in molecules]\ngraphs = [g for g in graphs if g is not None]\n\n# Augment the dataset\naugmented = augment_dataset(\n    graphs=graphs,\n    augmentation_methods=['edge_drop', 'feature_mask', 'edge_perturb'],\n    augment_percentage=1.0,  # Double the dataset\n    seed=42\n)\n\nprint(f\"Augmented {len(molecules)} molecules to {len(augmented)} graphs\")\n</code></pre>"},{"location":"graph_examples/#example-3-integration-with-machine-learning","title":"Example 3: Integration with Machine Learning","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch_geometric.loader import DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# Simple GNN for molecular property prediction\nclass MolecularGNN(nn.Module):\n    def __init__(self, num_node_features, hidden_dim=64):\n        super().__init__()\n        self.conv1 = GCNConv(num_node_features, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n        self.classifier = nn.Linear(hidden_dim, 1)\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x, edge_index, batch):\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.dropout(x)\n        x = F.relu(self.conv2(x, edge_index))\n        x = self.dropout(x)\n        x = F.relu(self.conv3(x, edge_index))\n\n        # Global pooling\n        x = global_mean_pool(x, batch)\n\n        return self.classifier(x)\n\n# Prepare data with augmentation\noriginal_graphs = graphs  # From previous example\naugmented_graphs = augment_dataset(\n    original_graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask'],\n    augment_percentage=0.3\n)\n\n# Add dummy targets for demonstration\nfor graph in augmented_graphs:\n    graph.y = torch.randn(1)  # Random property value\n\n# Split data\ntrain_graphs, test_graphs = train_test_split(\n    augmented_graphs, test_size=0.2, random_state=42\n)\n\n# Create data loaders\ntrain_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_graphs, batch_size=16, shuffle=False)\n\n# Initialize model\nmodel = MolecularGNN(num_node_features=9)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\n\n# Training loop\nmodel.train()\nfor epoch in range(10):\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n        out = model(batch.x, batch.edge_index, batch.batch)\n        loss = criterion(out, batch.y.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1:2d}, Loss: {total_loss/len(train_loader):.4f}\")\n\nprint(\"Training completed!\")\n</code></pre>"},{"location":"graph_examples/#example-4-comparative-analysis","title":"Example 4: Comparative Analysis","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n\ndef analyze_augmentation_impact(original_graphs, augmented_graphs):\n    \"\"\"Analyze the impact of augmentation on dataset statistics\"\"\"\n\n    # Extract statistics\n    def get_stats(graphs):\n        nodes = [g.num_nodes for g in graphs]\n        edges = [g.edge_index.size(1) for g in graphs]\n        return nodes, edges\n\n    orig_nodes, orig_edges = get_stats(original_graphs)\n    aug_nodes, aug_edges = get_stats(augmented_graphs)\n\n    # Create comparison plots\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n    # Node distribution\n    axes[0, 0].hist(orig_nodes, bins=20, alpha=0.7, label='Original', color='blue')\n    axes[0, 0].hist(aug_nodes, bins=20, alpha=0.7, label='Augmented', color='red')\n    axes[0, 0].set_xlabel('Number of Nodes')\n    axes[0, 0].set_ylabel('Frequency')\n    axes[0, 0].set_title('Node Count Distribution')\n    axes[0, 0].legend()\n\n    # Edge distribution\n    axes[0, 1].hist(orig_edges, bins=20, alpha=0.7, label='Original', color='blue')\n    axes[0, 1].hist(aug_edges, bins=20, alpha=0.7, label='Augmented', color='red')\n    axes[0, 1].set_xlabel('Number of Edges')\n    axes[0, 1].set_ylabel('Frequency')\n    axes[0, 1].set_title('Edge Count Distribution')\n    axes[0, 1].legend()\n\n    # Node vs Edge scatter\n    axes[1, 0].scatter(orig_nodes, orig_edges, alpha=0.6, label='Original', color='blue')\n    axes[1, 0].scatter(aug_nodes, aug_edges, alpha=0.6, label='Augmented', color='red')\n    axes[1, 0].set_xlabel('Number of Nodes')\n    axes[1, 0].set_ylabel('Number of Edges')\n    axes[1, 0].set_title('Nodes vs Edges Relationship')\n    axes[1, 0].legend()\n\n    # Statistics summary\n    stats_text = f\"\"\"Dataset Statistics:\n\nOriginal Dataset:\n\u2022 Graphs: {len(original_graphs)}\n\u2022 Avg nodes: {np.mean(orig_nodes):.1f} \u00b1 {np.std(orig_nodes):.1f}\n\u2022 Avg edges: {np.mean(orig_edges):.1f} \u00b1 {np.std(orig_edges):.1f}\n\nAugmented Dataset:\n\u2022 Graphs: {len(augmented_graphs)}\n\u2022 Avg nodes: {np.mean(aug_nodes):.1f} \u00b1 {np.std(aug_nodes):.1f}\n\u2022 Avg edges: {np.mean(aug_edges):.1f} \u00b1 {np.std(aug_edges):.1f}\n\nAugmentation Impact:\n\u2022 Size increase: {((len(augmented_graphs)/len(original_graphs))-1)*100:.1f}%\n\u2022 Node diversity: {(np.std(aug_nodes)/np.std(orig_nodes)-1)*100:+.1f}%\n\u2022 Edge diversity: {(np.std(aug_edges)/np.std(orig_edges)-1)*100:+.1f}%\"\"\"\n\n    axes[1, 1].text(0.05, 0.95, stats_text, transform=axes[1, 1].transAxes,\n                   fontsize=10, verticalalignment='top', fontfamily='monospace',\n                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n    axes[1, 1].set_xlim(0, 1)\n    axes[1, 1].set_ylim(0, 1)\n    axes[1, 1].axis('off')\n    axes[1, 1].set_title('Dataset Comparison')\n\n    plt.tight_layout()\n    plt.show()\n\n# Run analysis\nanalyze_augmentation_impact(graphs, augmented_graphs)\n</code></pre>"},{"location":"graph_examples/#example-5-advanced-augmentation-strategy","title":"Example 5: Advanced Augmentation Strategy","text":"<pre><code>from augchem.modules.graph.graphs_modules import (\n    edge_dropping, node_dropping, feature_masking, edge_perturbation\n)\n\ndef create_diverse_augmentations(graph, num_variants=5):\n    \"\"\"Create diverse augmentations of a single graph\"\"\"\n\n    variants = []\n\n    for i in range(num_variants):\n        # Randomly select augmentation parameters\n        edge_drop_rate = np.random.uniform(0.05, 0.15)\n        node_drop_rate = np.random.uniform(0.02, 0.08)\n        mask_rate = np.random.uniform(0.10, 0.20)\n\n        # Apply different combinations\n        if i % 3 == 0:\n            # Edge-focused augmentation\n            variant = edge_dropping(graph, drop_rate=edge_drop_rate)\n            variant = feature_masking(variant, mask_rate=mask_rate)\n            variant.augmentation_type = \"edge_focused\"\n\n        elif i % 3 == 1:\n            # Node-focused augmentation\n            variant = node_dropping(graph, drop_rate=node_drop_rate)\n            variant = feature_masking(variant, mask_rate=mask_rate)\n            variant.augmentation_type = \"node_focused\"\n\n        else:\n            # Perturbation-focused augmentation\n            variant = edge_perturbation(graph, add_rate=0.03, remove_rate=0.05)\n            variant = feature_masking(variant, mask_rate=mask_rate)\n            variant.augmentation_type = \"perturbation_focused\"\n\n        variants.append(variant)\n\n    return variants\n\n# Apply diverse augmentation to each graph\ndiverse_augmented = []\nfor i, graph in enumerate(graphs):\n    variants = create_diverse_augmentations(graph, num_variants=3)\n    diverse_augmented.extend(variants)\n    print(f\"Graph {i}: created {len(variants)} variants\")\n\nprint(f\"Total augmented graphs: {len(diverse_augmented)}\")\n\n# Analyze augmentation types\naugmentation_types = [g.augmentation_type for g in diverse_augmented]\ntype_counts = {t: augmentation_types.count(t) for t in set(augmentation_types)}\nprint(\"Augmentation type distribution:\", type_counts)\n</code></pre>"},{"location":"graph_examples/#example-6-individual-augmentation-techniques","title":"Example 6: Individual Augmentation Techniques","text":"<pre><code>from augchem.modules.graph.graphs_modules import (\n    edge_dropping, node_dropping, feature_masking, edge_perturbation\n)\n\n# Use a sample graph for demonstration\nsample_graph = graphs[0]  # Ethanol graph from previous example\n\nprint(\"Original graph statistics:\")\nprint(f\"  Nodes: {sample_graph.num_nodes}\")\nprint(f\"  Edges: {sample_graph.edge_index.size(1)}\")\nprint(f\"  Node features shape: {sample_graph.x.shape}\")\nprint(f\"  Edge features shape: {sample_graph.edge_attr.shape}\")\nprint()\n\n# 1. Edge Dropping\nprint(\"1. Edge Dropping:\")\nfor drop_rate in [0.1, 0.2, 0.3]:\n    edge_dropped = edge_dropping(sample_graph, drop_rate=drop_rate)\n    edges_removed = sample_graph.edge_index.size(1) - edge_dropped.edge_index.size(1)\n    print(f\"  Drop rate {drop_rate:.1f}: {sample_graph.edge_index.size(1)} -&gt; {edge_dropped.edge_index.size(1)} edges ({edges_removed} removed)\")\n\nprint()\n\n# 2. Node Dropping\nprint(\"2. Node Dropping:\")\nfor drop_rate in [0.05, 0.1, 0.15]:\n    node_dropped = node_dropping(sample_graph, drop_rate=drop_rate)\n    nodes_removed = sample_graph.num_nodes - node_dropped.num_nodes\n    print(f\"  Drop rate {drop_rate:.2f}: {sample_graph.num_nodes} -&gt; {node_dropped.num_nodes} nodes ({nodes_removed} removed)\")\n\nprint()\n\n# 3. Feature Masking\nprint(\"3. Feature Masking:\")\nfor mask_rate in [0.1, 0.2, 0.3]:\n    feature_masked = feature_masking(sample_graph, mask_rate=mask_rate)\n    total_features = feature_masked.x.numel()\n    masked_features = (feature_masked.x == float('-inf')).sum().item()\n    print(f\"  Mask rate {mask_rate:.1f}: {masked_features}/{total_features} features masked ({masked_features/total_features*100:.1f}%)\")\n\nprint()\n\n# 4. Edge Perturbation\nprint(\"4. Edge Perturbation:\")\nperturbation_configs = [\n    (0.05, 0.05),\n    (0.1, 0.1),\n    (0.03, 0.07)\n]\n\nfor add_rate, remove_rate in perturbation_configs:\n    edge_perturbed = edge_perturbation(sample_graph, add_rate=add_rate, remove_rate=remove_rate)\n    edge_change = edge_perturbed.edge_index.size(1) - sample_graph.edge_index.size(1)\n    print(f\"  Add {add_rate:.2f}, Remove {remove_rate:.2f}: {sample_graph.edge_index.size(1)} -&gt; {edge_perturbed.edge_index.size(1)} edges ({edge_change:+d} net change)\")\n</code></pre>"},{"location":"graph_examples/#example-7-batch-processing-and-quality-control","title":"Example 7: Batch Processing and Quality Control","text":"<pre><code>from torch_geometric.loader import DataLoader\n\ndef validate_graph_quality(graphs):\n    \"\"\"Check graph quality after augmentation\"\"\"\n\n    issues = []\n\n    for i, graph in enumerate(graphs):\n        # Check for isolated nodes\n        edge_index = graph.edge_index\n        if edge_index.size(1) &gt; 0:\n            connected_nodes = torch.unique(edge_index.flatten())\n            isolated_nodes = graph.num_nodes - len(connected_nodes)\n            if isolated_nodes &gt; 0:\n                issues.append(f\"Graph {i}: {isolated_nodes} isolated nodes\")\n\n        # Check for self-loops\n        if edge_index.size(1) &gt; 0:\n            self_loops = (edge_index[0] == edge_index[1]).sum().item()\n            if self_loops &gt; 0:\n                issues.append(f\"Graph {i}: {self_loops} self-loops\")\n\n        # Check for negative features (from masking)\n        if torch.any(graph.x == float('-inf')):\n            masked_count = (graph.x == float('-inf')).sum().item()\n            issues.append(f\"Graph {i}: {masked_count} masked features\")\n\n    return issues\n\n# Create larger dataset for demonstration\nlarger_graphs = []\nfor i in range(20):\n    smiles_list = [\n        \"CCO\", \"CC(=O)O\", \"c1ccccc1\", \"CCN(CC)CC\", \"CC(C)O\",\n        \"CC(C)(C)O\", \"CC=O\", \"C1CCCCC1\", \"c1ccc2ccccc2c1\", \"CCCCO\"\n    ]\n    graph = smiles_to_graph(smiles_list[i % len(smiles_list)])\n    if graph is not None:\n        larger_graphs.append(graph)\n\nprint(f\"Created dataset with {len(larger_graphs)} graphs\")\n\n# Apply batch augmentation\nbatch_augmented = augment_dataset(\n    graphs=larger_graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask', 'edge_perturb'],\n    edge_drop_rate=0.12,\n    node_drop_rate=0.08,\n    feature_mask_rate=0.20,\n    edge_add_rate=0.05,\n    edge_remove_rate=0.05,\n    augment_percentage=0.6,\n    seed=42\n)\n\nprint(f\"Batch augmentation: {len(larger_graphs)} -&gt; {len(batch_augmented)} graphs\")\n\n# Quality validation\nprint(\"\\nQuality validation:\")\noriginal_issues = validate_graph_quality(larger_graphs)\naugmented_issues = validate_graph_quality(batch_augmented)\n\nprint(f\"Original dataset issues: {len(original_issues)}\")\nif original_issues:\n    for issue in original_issues[:5]:  # Show first 5 issues\n        print(f\"  {issue}\")\n\nprint(f\"Augmented dataset issues: {len(augmented_issues)}\")\nif augmented_issues:\n    for issue in augmented_issues[:5]:  # Show first 5 issues\n        print(f\"  {issue}\")\n\n# Create DataLoader for training\ntrain_loader = DataLoader(batch_augmented, batch_size=32, shuffle=True)\n\nprint(f\"\\nCreated DataLoader with batch size 32\")\nprint(f\"Number of batches: {len(train_loader)}\")\n\n# Examine first batch\nfor batch in train_loader:\n    print(f\"First batch: {batch.num_graphs} graphs, {batch.x.size(0)} total nodes\")\n    break\n</code></pre>"},{"location":"graph_examples/#example-8-real-world-drug-discovery-application","title":"Example 8: Real-World Drug Discovery Application","text":"<pre><code># Simulate a more complex drug discovery scenario\nimport pandas as pd\n\n# Create realistic molecular dataset\ndrug_molecules = [\n    \"CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O\",        # Ibuprofen\n    \"CC(=O)Oc1ccccc1C(=O)O\",                   # Aspirin\n    \"CC(=O)Nc1ccc(cc1)O\",                      # Paracetamol\n    \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\",           # Caffeine\n    \"Clc1ccc(cc1)C(c2ccccc2)N3CCCC3\",         # Loratadine\n    \"CC12CCC3C(C1CCC2O)CCC4=CC(=O)CCC34C\",    # Testosterone\n    \"CCN(CC)CCNC(=O)c1cc(ccc1OC)S(=O)(=O)N\",  # Sulpiride\n    \"Cc1ccc(cc1)C(=O)c2ccc(cc2)N(C)C\",        # Michler's ketone\n]\n\n# Convert to graphs\ndrug_graphs = []\ndrug_names = [\"Ibuprofen\", \"Aspirin\", \"Paracetamol\", \"Caffeine\", \n              \"Loratadine\", \"Testosterone\", \"Sulpiride\", \"Michler's ketone\"]\n\nfor smiles, name in zip(drug_molecules, drug_names):\n    graph = smiles_to_graph(smiles)\n    if graph is not None:\n        graph.name = name\n        graph.y = torch.randn(1)  # Simulated activity\n        drug_graphs.append(graph)\n\nprint(f\"Drug discovery dataset: {len(drug_graphs)} compounds\")\n\n# Apply pharmaceutical-grade augmentation\npharma_augmented = augment_dataset(\n    graphs=drug_graphs,\n    augmentation_methods=['edge_drop', 'feature_mask', 'edge_perturb'],\n    edge_drop_rate=0.08,      # Conservative for drugs\n    feature_mask_rate=0.12,   # Preserve chemical meaning\n    edge_add_rate=0.03,       # Minimal structural changes\n    edge_remove_rate=0.05,\n    augment_percentage=0.4,   # 40% expansion\n    seed=42\n)\n\nprint(f\"Pharmaceutical augmentation: {len(drug_graphs)} -&gt; {len(pharma_augmented)} compounds\")\n\n# Analyze by original compound\nprint(\"\\nAugmentation breakdown by compound:\")\ncompound_counts = {}\nfor graph in pharma_augmented:\n    if hasattr(graph, 'name'):\n        compound_counts[graph.name] = compound_counts.get(graph.name, 0) + 1\n    else:\n        # This is an augmented graph, try to find parent\n        compound_counts['Augmented'] = compound_counts.get('Augmented', 0) + 1\n\nfor compound, count in compound_counts.items():\n    print(f\"  {compound}: {count} variants\")\n\n# Prepare for virtual screening\nvirtual_library = DataLoader(pharma_augmented, batch_size=16, shuffle=False)\n\nprint(f\"\\nVirtual screening library prepared:\")\nprint(f\"  Total compounds: {len(pharma_augmented)}\")\nprint(f\"  Batches for screening: {len(virtual_library)}\")\n\n# Simulate screening results\nscreening_results = []\nfor batch in virtual_library:\n    # Simulate screening scores\n    scores = torch.randn(batch.num_graphs)\n    screening_results.extend(scores.tolist())\n\nprint(f\"  Screening completed: {len(screening_results)} scores generated\")\nprint(f\"  Top hit score: {max(screening_results):.3f}\")\nprint(f\"  Mean score: {sum(screening_results)/len(screening_results):.3f}\")\n</code></pre> <p>These examples demonstrate the comprehensive capabilities of AugChem's graph augmentation toolkit for molecular research, from basic data expansion to sophisticated drug discovery applications.</p>"},{"location":"graph_tutorial/","title":"Graph Augmentation Tutorial","text":"<p>This tutorial demonstrates how to use AugChem's graph augmentation capabilities for molecular data enhancement.</p>"},{"location":"graph_tutorial/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install augchem torch torch-geometric rdkit\n</code></pre>"},{"location":"graph_tutorial/#basic-setup","title":"Basic Setup","text":"<pre><code>import torch\nfrom torch_geometric.data import Data, DataLoader\nfrom torch_geometric.transforms import NormalizeFeatures\nfrom augchem.modules.graph.graphs_modules import (\n    augment_dataset, edge_dropping, node_dropping, \n    feature_masking, edge_perturbation\n)\n</code></pre>"},{"location":"graph_tutorial/#tutorial-1-loading-molecular-data","title":"Tutorial 1: Loading Molecular Data","text":""},{"location":"graph_tutorial/#creating-sample-molecular-graphs","title":"Creating Sample Molecular Graphs","text":"<pre><code># Create sample molecular graphs (representing small molecules)\ndef create_sample_graph():\n    \"\"\"Create a simple molecular graph (e.g., ethanol: C-C-O)\"\"\"\n    # Node features: [atomic_number, degree, formal_charge]\n    x = torch.tensor([[6, 1, 0], [6, 2, 0], [8, 1, 0]], dtype=torch.float)  # C, C, O\n    # Edge connections: C-C, C-O bonds (bidirectional)\n    edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, num_nodes=3)\n\n# Create a small dataset of graphs\ngraphs = [create_sample_graph() for _ in range(10)]\nprint(f\"Created {len(graphs)} sample molecular graphs\")\n</code></pre>"},{"location":"graph_tutorial/#understanding-graph-structure","title":"Understanding Graph Structure","text":"<pre><code># Examine a single molecular graph\nsample_graph = graphs[0]\n\nprint(f\"Number of atoms (nodes): {sample_graph.num_nodes}\")\nprint(f\"Number of bonds (edges): {sample_graph.edge_index.size(1)}\")\nprint(f\"Node features shape: {sample_graph.x.shape}\")\n\n# Node features (per atom):\n# [atomic_num, degree, formal_charge, hybridization, aromatic, \n#  radical_electrons, total_hydrogens, in_ring, mass]\n\n# Edge features (per bond):\n# [bond_type, aromatic, in_ring, conjugated]\n</code></pre>"},{"location":"graph_tutorial/#loading-from-sdf-files-optional","title":"Loading from SDF Files (Optional)","text":"<pre><code># If you have SDF files, you can use the TorchGeometricSDFLoader\n# from your_loader import TorchGeometricSDFLoader\n\n# loader = TorchGeometricSDFLoader(\n#     sdf_path=\"path/to/your/molecules.sdf\",\n#     transform=NormalizeFeatures()\n# )\n\n# molecules = loader.load_sdf(max_molecules=1000)\n# graphs = loader.convert_to_torch_geometric_graphs(add_self_loops=False)\n</code></pre>"},{"location":"graph_tutorial/#tutorial-2-individual-augmentation-techniques","title":"Tutorial 2: Individual Augmentation Techniques","text":""},{"location":"graph_tutorial/#edge-dropping","title":"Edge Dropping","text":"<pre><code># Remove 10% of molecular bonds\naugmented_graph = edge_dropping(sample_graph, drop_rate=0.1)\n\nprint(f\"Original bonds: {sample_graph.edge_index.size(1)}\")\nprint(f\"After edge dropping: {augmented_graph.edge_index.size(1)}\")\nprint(f\"Bonds removed: {sample_graph.edge_index.size(1) - augmented_graph.edge_index.size(1)}\")\n</code></pre>"},{"location":"graph_tutorial/#node-dropping","title":"Node Dropping","text":"<pre><code># Remove 5% of atoms\naugmented_graph = node_dropping(sample_graph, drop_rate=0.05)\n\nprint(f\"Original atoms: {sample_graph.num_nodes}\")\nprint(f\"After node dropping: {augmented_graph.num_nodes}\")\nprint(f\"Atoms removed: {sample_graph.num_nodes - augmented_graph.num_nodes}\")\n</code></pre>"},{"location":"graph_tutorial/#feature-masking","title":"Feature Masking","text":"<pre><code># Mask 15% of atomic features\naugmented_graph = feature_masking(sample_graph, mask_rate=0.15)\n\n# Check for masked features (they become -inf)\nmasked_features = (augmented_graph.x == float('-inf')).sum().item()\ntotal_features = augmented_graph.x.numel()\nmask_percentage = (masked_features / total_features) * 100\n\nprint(f\"Masked features: {masked_features}/{total_features} ({mask_percentage:.1f}%)\")\n</code></pre>"},{"location":"graph_tutorial/#edge-perturbation","title":"Edge Perturbation","text":"<pre><code># Add 3% new bonds and remove 3% existing bonds\naugmented_graph = edge_perturbation(\n    sample_graph, \n    add_rate=0.03, \n    remove_rate=0.03\n)\n\nprint(f\"Original bonds: {sample_graph.edge_index.size(1)}\")\nprint(f\"After perturbation: {augmented_graph.edge_index.size(1)}\")\n</code></pre>"},{"location":"graph_tutorial/#tutorial-3-comprehensive-dataset-augmentation","title":"Tutorial 3: Comprehensive Dataset Augmentation","text":""},{"location":"graph_tutorial/#basic-augmentation","title":"Basic Augmentation","text":"<pre><code># Apply multiple techniques to create an augmented dataset\naugmented_dataset = augment_dataset(\n    graphs=graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask'],\n    edge_drop_rate=0.1,\n    node_drop_rate=0.05,\n    feature_mask_rate=0.15,\n    augment_percentage=0.25,  # 25% more data\n    seed=42  # For reproducibility\n)\n\nprint(f\"Original dataset: {len(graphs)} graphs\")\nprint(f\"Augmented dataset: {len(augmented_dataset)} graphs\")\nprint(f\"New graphs added: {len(augmented_dataset) - len(graphs)}\")\n</code></pre>"},{"location":"graph_tutorial/#advanced-augmentation","title":"Advanced Augmentation","text":"<pre><code># Use all available techniques with custom parameters\naugmented_dataset = augment_dataset(\n    graphs=graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask', 'edge_perturb'],\n    edge_drop_rate=0.12,\n    node_drop_rate=0.08,\n    feature_mask_rate=0.20,\n    edge_add_rate=0.04,\n    edge_remove_rate=0.06,\n    augment_percentage=0.40,  # 40% more data\n    seed=42\n)\n\n# Check augmentation metadata\nfor i, graph in enumerate(augmented_dataset[-10:]):  # Last 10 graphs\n    if hasattr(graph, 'augmentation_method'):\n        print(f\"Graph {len(graphs) + i}: {graph.augmentation_method}\")\n        print(f\"  Parent graph: {graph.parent_idx}\")\n</code></pre>"},{"location":"graph_tutorial/#graph-augmentation-methods-summary","title":"Graph Augmentation Methods Summary","text":"Method Description Parameters Chemical Interpretation edge_drop Remove molecular bonds <code>drop_rate</code> Bond breaking simulation node_drop Remove atoms <code>drop_rate</code> Atomic deletion feature_mask Mask atom properties <code>mask_rate</code> Property uncertainty edge_perturb Add/remove bonds <code>add_rate</code>, <code>remove_rate</code> Chemical reaction simulation"},{"location":"graph_tutorial/#tutorial-4-batch-processing-and-training","title":"Tutorial 4: Batch Processing and Training","text":""},{"location":"graph_tutorial/#creating-dataloaders","title":"Creating DataLoaders","text":"<pre><code>from sklearn.model_selection import train_test_split\n\n# Split augmented dataset\ntrain_graphs, test_graphs = train_test_split(\n    augmented_dataset, \n    test_size=0.2, \n    random_state=42\n)\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n\nprint(f\"Training graphs: {len(train_graphs)}\")\nprint(f\"Testing graphs: {len(test_graphs)}\")\n</code></pre>"},{"location":"graph_tutorial/#analyzing-batches","title":"Analyzing Batches","text":"<pre><code># Examine a training batch\nfor batch in train_loader:\n    print(f\"Batch contains {batch.num_graphs} graphs\")\n    print(f\"Total nodes in batch: {batch.x.size(0)}\")\n    print(f\"Total edges in batch: {batch.edge_index.size(1)}\")\n    print(f\"Node features shape: {batch.x.shape}\")\n\n    # The batch tensor maps nodes to their respective graphs\n    print(f\"Batch assignment shape: {batch.batch.shape}\")\n    break\n</code></pre>"},{"location":"graph_tutorial/#tutorial-5-quality-control-and-validation","title":"Tutorial 5: Quality Control and Validation","text":""},{"location":"graph_tutorial/#self-loop-detection","title":"Self-Loop Detection","text":"<pre><code># Check for self-loops before augmentation\ndef check_self_loops(graphs):\n    total_self_loops = 0\n    for graph in graphs:\n        if graph.edge_index.size(1) &gt; 0:\n            self_loops = (graph.edge_index[0] == graph.edge_index[1]).sum().item()\n            total_self_loops += self_loops\n    return total_self_loops\n\noriginal_self_loops = check_self_loops(graphs)\naugmented_self_loops = check_self_loops(augmented_dataset)\n\nprint(f\"Self-loops in original dataset: {original_self_loops}\")\nprint(f\"Self-loops in augmented dataset: {augmented_self_loops}\")\n</code></pre>"},{"location":"graph_tutorial/#graph-statistics","title":"Graph Statistics","text":"<pre><code># Analyze dataset statistics\ndef analyze_dataset(graphs, name):\n    num_nodes = [g.num_nodes for g in graphs]\n    num_edges = [g.edge_index.size(1) for g in graphs]\n\n    print(f\"\\n{name} Dataset Statistics:\")\n    print(f\"  Total graphs: {len(graphs)}\")\n    print(f\"  Nodes per graph: {sum(num_nodes)/len(num_nodes):.1f} \u00b1 {torch.tensor(num_nodes).float().std():.1f}\")\n    print(f\"  Edges per graph: {sum(num_edges)/len(num_edges):.1f} \u00b1 {torch.tensor(num_edges).float().std():.1f}\")\n\nanalyze_dataset(graphs, \"Original\")\nanalyze_dataset(augmented_dataset, \"Augmented\")\n</code></pre>"},{"location":"graph_tutorial/#graph-validation","title":"Graph Validation","text":"<pre><code>def validate_graphs(graph_list):\n    \"\"\"Validate molecular graphs\"\"\"\n    stats = {\n        'total': len(graph_list),\n        'avg_nodes': sum(g.num_nodes for g in graph_list) / len(graph_list),\n        'avg_edges': sum(g.edge_index.size(1) for g in graph_list) / len(graph_list),\n        'isolated_nodes': 0,\n        'empty_graphs': 0\n    }\n\n    for graph in graph_list:\n        # Check for isolated nodes (nodes with no edges)\n        if graph.edge_index.size(1) == 0 and graph.num_nodes &gt; 0:\n            stats['isolated_nodes'] += 1\n\n        # Check for empty graphs\n        if graph.num_nodes == 0:\n            stats['empty_graphs'] += 1\n\n    return stats\n\n# Validate augmented graphs\ngraph_stats = validate_graphs(augmented_dataset)\nprint(\"Graph Statistics:\")\nfor key, value in graph_stats.items():\n    if isinstance(value, float):\n        print(f\"  {key}: {value:.2f}\")\n    else:\n        print(f\"  {key}: {value}\")\n</code></pre>"},{"location":"graph_tutorial/#tutorial-6-visualization-and-analysis","title":"Tutorial 6: Visualization and Analysis","text":""},{"location":"graph_tutorial/#augmentation-impact-analysis","title":"Augmentation Impact Analysis","text":"<pre><code>import matplotlib.pyplot as plt\n\n# Compare distributions\noriginal_nodes = [g.num_nodes for g in graphs]\naugmented_nodes = [g.num_nodes for g in augmented_dataset]\n\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.hist(original_nodes, bins=30, alpha=0.7, label='Original', color='blue')\nplt.hist(augmented_nodes, bins=30, alpha=0.7, label='Augmented', color='red')\nplt.xlabel('Number of Nodes')\nplt.ylabel('Frequency')\nplt.title('Node Count Distribution')\nplt.legend()\n\nplt.subplot(1, 2, 2)\noriginal_edges = [g.edge_index.size(1) for g in graphs]\naugmented_edges = [g.edge_index.size(1) for g in augmented_dataset]\n\nplt.hist(original_edges, bins=30, alpha=0.7, label='Original', color='blue')\nplt.hist(augmented_edges, bins=30, alpha=0.7, label='Augmented', color='red')\nplt.xlabel('Number of Edges')\nplt.ylabel('Frequency')\nplt.title('Edge Count Distribution')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"graph_tutorial/#advanced-graph-analysis","title":"Advanced Graph Analysis","text":"<pre><code>def comprehensive_graph_analysis(graphs, name):\n    \"\"\"Comprehensive analysis of graph dataset\"\"\"\n\n    # Basic statistics\n    num_nodes = [g.num_nodes for g in graphs]\n    num_edges = [g.edge_index.size(1) for g in graphs]\n\n    # Calculate degree statistics\n    degrees = []\n    for graph in graphs:\n        if graph.edge_index.size(1) &gt; 0:\n            from torch_geometric.utils import degree\n            deg = degree(graph.edge_index[0], num_nodes=graph.num_nodes)\n            degrees.extend(deg.tolist())\n\n    stats = {\n        'num_graphs': len(graphs),\n        'avg_nodes': sum(num_nodes) / len(num_nodes),\n        'avg_edges': sum(num_edges) / len(num_edges),\n        'avg_degree': sum(degrees) / len(degrees) if degrees else 0,\n        'max_nodes': max(num_nodes) if num_nodes else 0,\n        'max_edges': max(num_edges) if num_edges else 0\n    }\n\n    print(f\"\\n{name} Analysis:\")\n    for key, value in stats.items():\n        print(f\"  {key}: {value:.2f}\")\n\n    return stats\n\n# Comprehensive analysis\noriginal_stats = comprehensive_graph_analysis(graphs, \"Original\")\naugmented_stats = comprehensive_graph_analysis(augmented_dataset, \"Augmented\")\n</code></pre>"},{"location":"graph_tutorial/#tutorial-7-integration-with-graph-neural-networks","title":"Tutorial 7: Integration with Graph Neural Networks","text":""},{"location":"graph_tutorial/#simple-gnn-example","title":"Simple GNN Example","text":"<pre><code>import torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, global_mean_pool\n\nclass MolecularGNN(nn.Module):\n    def __init__(self, num_features, hidden_dim=64, num_classes=1):\n        super().__init__()\n        self.conv1 = GCNConv(num_features, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.classifier = nn.Linear(hidden_dim, num_classes)\n\n    def forward(self, x, edge_index, batch):\n        # Graph convolutions\n        x = F.relu(self.conv1(x, edge_index))\n        x = F.relu(self.conv2(x, edge_index))\n\n        # Global pooling\n        x = global_mean_pool(x, batch)\n\n        # Classification\n        return self.classifier(x)\n\n# Initialize model\nmodel = MolecularGNN(num_features=graphs[0].x.size(1))\n\n# Training loop example\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\n\nmodel.train()\nfor epoch in range(5):\n    total_loss = 0\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        # Forward pass\n        out = model(batch.x, batch.edge_index, batch.batch)\n\n        # Dummy target for demonstration\n        target = torch.randn(batch.num_graphs, 1)\n\n        # Loss and backprop\n        loss = criterion(out, target)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n</code></pre>"},{"location":"graph_tutorial/#advanced-gnn-with-augmented-data","title":"Advanced GNN with Augmented Data","text":"<pre><code># More sophisticated training with augmented data\ndef train_with_augmentation():\n    \"\"\"Training loop that leverages augmented data\"\"\"\n\n    # Create augmented dataset with labels\n    augmented_graphs_with_targets = []\n    for graph in augmented_dataset:\n        graph.y = torch.randn(1)  # Random target for demo\n        augmented_graphs_with_targets.append(graph)\n\n    # Split and create loaders\n    train_graphs, val_graphs = train_test_split(\n        augmented_graphs_with_targets, test_size=0.2, random_state=42\n    )\n\n    train_loader = DataLoader(train_graphs, batch_size=16, shuffle=True)\n    val_loader = DataLoader(val_graphs, batch_size=16, shuffle=False)\n\n    model = MolecularGNN(num_features=graphs[0].x.size(1))\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.MSELoss()\n\n    # Training with validation\n    for epoch in range(10):\n        # Train\n        model.train()\n        train_loss = 0\n        for batch in train_loader:\n            optimizer.zero_grad()\n            out = model(batch.x, batch.edge_index, batch.batch)\n            loss = criterion(out, batch.y.view(-1, 1))\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n\n        # Validate\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                out = model(batch.x, batch.edge_index, batch.batch)\n                loss = criterion(out, batch.y.view(-1, 1))\n                val_loss += loss.item()\n\n        print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(train_loader):.4f}, \"\n              f\"Val Loss: {val_loss/len(val_loader):.4f}\")\n\n# Run advanced training\n# train_with_augmentation()\n</code></pre>"},{"location":"graph_tutorial/#best-practices-for-graph-augmentation","title":"Best Practices for Graph Augmentation","text":""},{"location":"graph_tutorial/#1-data-preparation","title":"1. Data Preparation","text":"<ul> <li>Always check for self-loops before augmentation</li> <li>Use transforms without <code>AddSelfLoops</code> for augmentation workflows</li> <li>Validate graph integrity after augmentation</li> </ul>"},{"location":"graph_tutorial/#2-augmentation-strategy","title":"2. Augmentation Strategy","text":"<ul> <li>Start with conservative augmentation rates (5-15%)</li> <li>Monitor the impact on model performance</li> <li>Use different techniques for different aspects of robustness</li> </ul>"},{"location":"graph_tutorial/#3-reproducibility","title":"3. Reproducibility","text":"<ul> <li>Always set random seeds for experiments</li> <li>Document augmentation parameters</li> <li>Save augmented datasets for reuse</li> </ul>"},{"location":"graph_tutorial/#4-performance-optimization","title":"4. Performance Optimization","text":"<ul> <li>Use appropriate batch sizes for your hardware</li> <li>Profile memory usage for large datasets</li> <li>Consider distributed processing for very large datasets</li> </ul>"},{"location":"graph_tutorial/#5-validation","title":"5. Validation","text":"<ul> <li>Compare augmented vs original performance</li> <li>Use cross-validation with consistent augmentation</li> <li>Monitor for data leakage between train/test sets</li> </ul>"},{"location":"graph_tutorial/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"graph_tutorial/#self-loops-causing-errors","title":"Self-loops Causing Errors","text":"<pre><code># Remove self-loops before augmentation\nfrom torch_geometric.utils import remove_self_loops\n\ndef clean_graphs(graphs):\n    cleaned = []\n    for graph in graphs:\n        edge_index, edge_attr = remove_self_loops(graph.edge_index, graph.edge_attr)\n        cleaned_graph = Data(\n            x=graph.x,\n            edge_index=edge_index,\n            edge_attr=edge_attr,\n            num_nodes=graph.num_nodes\n        )\n        cleaned.append(cleaned_graph)\n    return cleaned\n\n# Apply cleaning\nclean_graphs_list = clean_graphs(graphs)\n</code></pre>"},{"location":"graph_tutorial/#memory-issues","title":"Memory Issues","text":"<pre><code># Process in smaller batches\ndef memory_efficient_augmentation(graphs, batch_size=100):\n    all_augmented = []\n\n    for i in range(0, len(graphs), batch_size):\n        batch_graphs = graphs[i:i+batch_size]\n\n        batch_augmented = augment_dataset(\n            graphs=batch_graphs,\n            augmentation_methods=['edge_drop'],\n            augment_percentage=0.2\n        )\n\n        all_augmented.extend(batch_augmented)\n        print(f\"Processed batch {i//batch_size + 1}\")\n\n    return all_augmented\n\n# Use for large datasets\n# large_augmented = memory_efficient_augmentation(large_graph_list)\n</code></pre>"},{"location":"graph_tutorial/#edge-attribute-mismatches","title":"Edge Attribute Mismatches","text":"<pre><code># Validate edge attributes\ndef validate_edge_attributes(graphs):\n    for i, graph in enumerate(graphs):\n        if hasattr(graph, 'edge_attr') and graph.edge_attr is not None:\n            if graph.edge_attr.size(0) != graph.edge_index.size(1):\n                print(f\"Graph {i}: Edge attribute mismatch!\")\n                print(f\"  Edge index: {graph.edge_index.size(1)} edges\")\n                print(f\"  Edge attr: {graph.edge_attr.size(0)} attributes\")\n\n# Check before augmentation\nvalidate_edge_attributes(graphs)\n</code></pre>"},{"location":"graph_tutorial/#saving-and-loading-augmented-graphs","title":"Saving and Loading Augmented Graphs","text":"<pre><code># Save augmented dataset\ntorch.save(augmented_dataset, \"augmented_molecular_graphs.pt\")\nprint(f\"Saved {len(augmented_dataset)} graphs\")\n\n# Load augmented dataset\nloaded_graphs = torch.load(\"augmented_molecular_graphs.pt\")\nprint(f\"Loaded {len(loaded_graphs)} graphs\")\n\n# Save with metadata\naugmentation_info = {\n    'graphs': augmented_dataset,\n    'parameters': {\n        'edge_drop_rate': 0.1,\n        'node_drop_rate': 0.05,\n        'augment_percentage': 0.25,\n        'seed': 42\n    },\n    'original_count': len(graphs),\n    'augmented_count': len(augmented_dataset)\n}\n\ntorch.save(augmentation_info, \"augmented_graphs_with_metadata.pt\")\n</code></pre>"},{"location":"graph_tutorial/#next-steps","title":"Next Steps","text":"<p>After completing this graph tutorial:</p> <ul> <li>\u2705 Master all graph augmentation techniques</li> <li>\u2705 Implement quality control and validation</li> <li>\u2705 Integrate with PyTorch Geometric workflows</li> <li>\u2705 Build and train Graph Neural Networks</li> <li>\u2705 Handle large molecular datasets efficiently</li> </ul>"},{"location":"graph_tutorial/#see-also","title":"See Also","text":"<ul> <li>SMILES Augmentation Tutorial - Learn string-based augmentation</li> <li>Graph Methods API - Complete method documentation</li> <li>Examples - Real-world applications</li> </ul>"},{"location":"smiles_examples/","title":"SMILES Examples","text":"<p>This section provides practical examples of using AugChem for SMILES-based molecular data augmentation.</p>"},{"location":"smiles_examples/#example-1-basic-smiles-augmentation","title":"Example 1: Basic SMILES Augmentation","text":"<pre><code>from augchem import Augmentator\nfrom augchem.modules.smiles.smiles_modules import (\n    mask, delete, swap, fusion, enumerateSmiles, tokenize\n)\nimport pandas as pd\n\n# Initialize augmentator\naugmentator = Augmentator(seed=42)\n\n# Sample SMILES molecules\nmolecules = [\n    \"CCO\",                    # Ethanol\n    \"CC(=O)O\",               # Acetic acid\n    \"c1ccccc1\",              # Benzene\n    \"CC(C)O\",                # Isopropanol\n    \"C1=CC=C(C=C1)O\",        # Phenol\n    \"CCN(CC)CC\",             # Triethylamine\n    \"CC(C)(C)O\",             # tert-Butanol\n    \"C1=CC=C2C(=C1)C=CC=C2\", # Naphthalene\n]\n\nprint(\"Original SMILES molecules:\")\nfor i, smiles in enumerate(molecules):\n    print(f\"{i+1:2d}. {smiles}\")\n</code></pre>"},{"location":"smiles_examples/#example-2-individual-augmentation-methods","title":"Example 2: Individual Augmentation Methods","text":"<pre><code># Demonstrate each augmentation method\noriginal = \"CC(=O)Oc1ccccc1C(=O)O\"  # Aspirin\nprint(f\"Original molecule: {original}\")\nprint()\n\n# 1. Tokenization - understand structure\ntokens = tokenize(original)\nprint(f\"Tokens: {tokens}\")\nprint(f\"Token count: {len(tokens)}\")\nprint()\n\n# 2. Masking - replace tokens with [M]\nmasked_variants = []\nfor ratio in [0.1, 0.2, 0.3]:\n    masked = mask(original, mask_ratio=ratio, seed=42)\n    masked_variants.append(masked)\n    print(f\"Masked ({ratio:.1f}): {masked}\")\n\nprint()\n\n# 3. Deletion - remove random tokens\ndeleted_variants = []\nfor ratio in [0.1, 0.2, 0.3]:\n    deleted = delete(original, delete_ratio=ratio, seed=42)\n    deleted_variants.append(deleted)\n    print(f\"Deleted ({ratio:.1f}): {deleted}\")\n\nprint()\n\n# 4. Swapping - exchange atom positions\nswapped_variants = []\nfor i in range(3):  # Multiple random swaps\n    swapped = swap(original, seed=42+i)\n    swapped_variants.append(swapped)\n    print(f\"Swapped #{i+1}: {swapped}\")\n\nprint()\n\n# 5. Fusion - combined methods\nfusion_variants = []\nfor i in range(3):\n    fused = fusion(original, mask_ratio=0.1, delete_ratio=0.15, seed=42+i)\n    fusion_variants.append(fused)\n    print(f\"Fusion #{i+1}: {fused}\")\n\nprint()\n\n# 6. Enumeration - non-canonical SMILES\nenumerated_variants = []\nfor i in range(5):\n    enumerated = enumerateSmiles(original)\n    enumerated_variants.append(enumerated)\n    print(f\"Enumerated #{i+1}: {enumerated}\")\n</code></pre>"},{"location":"smiles_examples/#example-3-dataset-level-augmentation","title":"Example 3: Dataset-Level Augmentation","text":"<pre><code># Create a molecular dataset with properties\ndata = {\n    'SMILES': [\n        'CCO',                    # Ethanol\n        'CC(=O)O',               # Acetic acid\n        'c1ccccc1',              # Benzene\n        'CC(C)O',                # Isopropanol\n        'C1=CC=C(C=C1)O',        # Phenol\n        'CCN(CC)CC',             # Triethylamine\n        'CC(C)(C)O',             # tert-Butanol\n        'C1=CC=C2C(=C1)C=CC=C2', # Naphthalene\n        'CC(=O)Nc1ccc(cc1)O',    # Paracetamol\n        'CC(=O)Oc1ccccc1C(=O)O'  # Aspirin\n    ],\n    'LogP': [\u22120.31, \u22120.17, 2.13, 0.05, 1.46, 1.45, 0.35, 3.30, 0.46, 1.19],\n    'MW': [46.07, 60.05, 78.11, 60.10, 94.11, 101.19, 74.12, 128.17, 151.16, 180.16],\n    'Activity': [0, 0, 1, 0, 1, 0, 0, 1, 1, 1]\n}\n\ndf = pd.DataFrame(data)\ndf.to_csv('molecular_dataset.csv', index=False)\n\nprint(f\"Created dataset with {len(df)} molecules\")\nprint(df.head())\n</code></pre>"},{"location":"smiles_examples/#example-4-comprehensive-augmentation-strategy","title":"Example 4: Comprehensive Augmentation Strategy","text":"<pre><code>from augchem.modules.smiles.smiles_modules import augment_dataset\n\n# Load the dataset\ndf = pd.read_csv('molecular_dataset.csv')\n\n# Apply comprehensive augmentation\naugmented_df = augment_dataset(\n    col_to_augment=\"SMILES\",\n    dataset=df,\n    augmentation_methods=[\"mask\", \"delete\", \"fusion\", \"enumeration\"],\n    mask_ratio=0.15,\n    delete_ratio=0.25,\n    augment_percentage=0.6,  # 60% more molecules\n    property_col=\"LogP\",     # Preserve LogP values\n    seed=42\n)\n\nprint(f\"Dataset expanded from {len(df)} to {len(augmented_df)} molecules\")\nprint(f\"New molecules added: {len(augmented_df) - len(df)}\")\n\n# Save augmented dataset\naugmented_df.to_csv('augmented_molecular_dataset.csv', index=False)\n\n# Analyze augmentation results\nprint(\"\\nAugmentation Analysis:\")\noriginal_count = augmented_df['parent_idx'].isna().sum()\naugmented_count = len(augmented_df) - original_count\n\nprint(f\"Original molecules: {original_count}\")\nprint(f\"Augmented molecules: {augmented_count}\")\nprint(f\"Augmentation ratio: {augmented_count/original_count:.2f}\")\n</code></pre>"},{"location":"smiles_examples/#example-5-using-the-main-augmentator-class","title":"Example 5: Using the Main Augmentator Class","text":"<pre><code># Initialize with custom parameters\naugmentator = Augmentator(seed=123)\n\n# Method 1: Direct augmentation\nresult = augmentator.SMILES.augment_data(\n    dataset=\"molecular_dataset.csv\",\n    augmentation_methods=[\"fusion\", \"enumeration\", \"mask\"],\n    mask_ratio=0.20,\n    delete_ratio=0.30,\n    augment_percentage=0.5,\n    col_to_augment=\"SMILES\",\n    property_col=\"MW\"  # Preserve molecular weight\n)\n\nprint(f\"Augmented dataset size: {len(result)}\")\n\n# Method 2: Step-by-step processing\ndf = pd.read_csv('molecular_dataset.csv')\n\n# Apply different methods to different subsets\nsubset1 = df.iloc[:5]  # First 5 molecules\nsubset2 = df.iloc[5:]  # Remaining molecules\n\n# Conservative augmentation for subset 1\naug1 = augmentator.SMILES.augment_data(\n    dataset=subset1,\n    augmentation_methods=[\"enumeration\"],\n    augment_percentage=0.3,\n    col_to_augment=\"SMILES\",\n    property_col=\"Activity\"\n)\n\n# Aggressive augmentation for subset 2\naug2 = augmentator.SMILES.augment_data(\n    dataset=subset2,\n    augmentation_methods=[\"mask\", \"delete\", \"fusion\"],\n    mask_ratio=0.25,\n    delete_ratio=0.35,\n    augment_percentage=0.8,\n    col_to_augment=\"SMILES\",\n    property_col=\"Activity\"\n)\n\n# Combine results\ncombined_result = pd.concat([aug1, aug2], ignore_index=True)\nprint(f\"Combined augmented dataset: {len(combined_result)} molecules\")\n</code></pre>"},{"location":"smiles_examples/#example-6-quality-control-and-validation","title":"Example 6: Quality Control and Validation","text":"<pre><code>from rdkit import Chem\nfrom rdkit.Chem import Descriptors\nimport matplotlib.pyplot as plt\n\ndef validate_and_analyze_smiles(df, smiles_col='SMILES'):\n    \"\"\"Comprehensive SMILES validation and analysis\"\"\"\n\n    valid_smiles = []\n    invalid_smiles = []\n    molecular_weights = []\n    logp_values = []\n\n    for smiles in df[smiles_col]:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol is not None:\n            valid_smiles.append(smiles)\n            molecular_weights.append(Descriptors.MolWt(mol))\n            logp_values.append(Descriptors.MolLogP(mol))\n        else:\n            invalid_smiles.append(smiles)\n\n    # Print validation results\n    print(f\"Validation Results:\")\n    print(f\"  Valid SMILES: {len(valid_smiles)}/{len(df)} ({len(valid_smiles)/len(df)*100:.1f}%)\")\n    print(f\"  Invalid SMILES: {len(invalid_smiles)}\")\n\n    if invalid_smiles:\n        print(f\"  Examples of invalid SMILES: {invalid_smiles[:3]}\")\n\n    # Calculate statistics\n    if molecular_weights:\n        print(f\"\\nMolecular Weight Statistics:\")\n        print(f\"  Mean: {sum(molecular_weights)/len(molecular_weights):.2f}\")\n        print(f\"  Range: {min(molecular_weights):.2f} - {max(molecular_weights):.2f}\")\n\n        print(f\"\\nLogP Statistics:\")\n        print(f\"  Mean: {sum(logp_values)/len(logp_values):.2f}\")\n        print(f\"  Range: {min(logp_values):.2f} - {max(logp_values):.2f}\")\n\n    return valid_smiles, invalid_smiles, molecular_weights, logp_values\n\n# Validate original dataset\nprint(\"=== Original Dataset Validation ===\")\norig_valid, orig_invalid, orig_mw, orig_logp = validate_and_analyze_smiles(df)\n\n# Validate augmented dataset\nprint(\"\\n=== Augmented Dataset Validation ===\")\naug_valid, aug_invalid, aug_mw, aug_logp = validate_and_analyze_smiles(augmented_df)\n\n# Visualize distributions\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Molecular weight distributions\naxes[0, 0].hist(orig_mw, bins=20, alpha=0.7, label='Original', color='blue')\naxes[0, 0].hist(aug_mw, bins=20, alpha=0.7, label='Augmented', color='red')\naxes[0, 0].set_xlabel('Molecular Weight')\naxes[0, 0].set_ylabel('Frequency')\naxes[0, 0].set_title('Molecular Weight Distribution')\naxes[0, 0].legend()\n\n# LogP distributions\naxes[0, 1].hist(orig_logp, bins=20, alpha=0.7, label='Original', color='blue')\naxes[0, 1].hist(aug_logp, bins=20, alpha=0.7, label='Augmented', color='red')\naxes[0, 1].set_xlabel('LogP')\naxes[0, 1].set_ylabel('Frequency')\naxes[0, 1].set_title('LogP Distribution')\naxes[0, 1].legend()\n\n# SMILES length analysis\norig_lengths = [len(s) for s in df['SMILES']]\naug_lengths = [len(s) for s in augmented_df['SMILES']]\n\naxes[1, 0].hist(orig_lengths, bins=20, alpha=0.7, label='Original', color='blue')\naxes[1, 0].hist(aug_lengths, bins=20, alpha=0.7, label='Augmented', color='red')\naxes[1, 0].set_xlabel('SMILES Length')\naxes[1, 0].set_ylabel('Frequency')\naxes[1, 0].set_title('SMILES String Length Distribution')\naxes[1, 0].legend()\n\n# Summary statistics\nstats_text = f\"\"\"Dataset Quality Summary:\n\nOriginal Dataset:\n\u2022 Total molecules: {len(df)}\n\u2022 Valid SMILES: {len(orig_valid)} ({len(orig_valid)/len(df)*100:.1f}%)\n\u2022 Avg MW: {sum(orig_mw)/len(orig_mw):.1f}\n\u2022 Avg LogP: {sum(orig_logp)/len(orig_logp):.2f}\n\u2022 Avg length: {sum(orig_lengths)/len(orig_lengths):.1f}\n\nAugmented Dataset:\n\u2022 Total molecules: {len(augmented_df)}\n\u2022 Valid SMILES: {len(aug_valid)} ({len(aug_valid)/len(augmented_df)*100:.1f}%)\n\u2022 Avg MW: {sum(aug_mw)/len(aug_mw):.1f}\n\u2022 Avg LogP: {sum(aug_logp)/len(aug_logp):.2f}\n\u2022 Avg length: {sum(aug_lengths)/len(aug_lengths):.1f}\n\nQuality Metrics:\n\u2022 Validity preservation: {len(aug_valid)/len(augmented_df)*100:.1f}%\n\u2022 Chemical diversity maintained: \u2713\n\u2022 Property distributions preserved: \u2713\"\"\"\n\naxes[1, 1].text(0.05, 0.95, stats_text, transform=axes[1, 1].transAxes,\n               fontsize=9, verticalalignment='top', fontfamily='monospace',\n               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\naxes[1, 1].set_xlim(0, 1)\naxes[1, 1].set_ylim(0, 1)\naxes[1, 1].axis('off')\naxes[1, 1].set_title('Quality Assessment')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"smiles_examples/#example-7-advanced-augmentation-strategies","title":"Example 7: Advanced Augmentation Strategies","text":"<pre><code>def create_stratified_augmentation(df, target_col, smiles_col='SMILES'):\n    \"\"\"Apply different augmentation strategies based on target variable\"\"\"\n\n    augmented_dfs = []\n\n    # Get unique classes\n    classes = df[target_col].unique()\n\n    for class_val in classes:\n        class_df = df[df[target_col] == class_val].copy()\n\n        if class_val == 0:  # Inactive compounds - conservative augmentation\n            aug_df = augment_dataset(\n                col_to_augment=smiles_col,\n                dataset=class_df,\n                augmentation_methods=[\"enumeration\"],\n                augment_percentage=0.3,\n                property_col=target_col,\n                seed=42\n            )\n            print(f\"Class {class_val}: Conservative augmentation ({len(class_df)} -&gt; {len(aug_df)})\")\n\n        else:  # Active compounds - aggressive augmentation\n            aug_df = augment_dataset(\n                col_to_augment=smiles_col,\n                dataset=class_df,\n                augmentation_methods=[\"mask\", \"fusion\", \"enumeration\"],\n                mask_ratio=0.20,\n                delete_ratio=0.25,\n                augment_percentage=0.8,\n                property_col=target_col,\n                seed=42\n            )\n            print(f\"Class {class_val}: Aggressive augmentation ({len(class_df)} -&gt; {len(aug_df)})\")\n\n        augmented_dfs.append(aug_df)\n\n    # Combine all classes\n    final_df = pd.concat(augmented_dfs, ignore_index=True)\n    return final_df\n\n# Apply stratified augmentation\nstratified_result = create_stratified_augmentation(df, 'Activity')\n\nprint(f\"\\nStratified augmentation results:\")\nprint(f\"Final dataset size: {len(stratified_result)}\")\n\n# Analyze class distribution\nclass_dist = stratified_result['Activity'].value_counts().sort_index()\nprint(f\"Class distribution after augmentation:\")\nfor class_val, count in class_dist.items():\n    print(f\"  Class {class_val}: {count} molecules\")\n</code></pre>"},{"location":"smiles_examples/#example-8-real-world-application-drug-discovery","title":"Example 8: Real-World Application - Drug Discovery","text":"<pre><code># Simulate a drug discovery dataset\ndrug_data = {\n    'SMILES': [\n        'CC(C)Cc1ccc(cc1)[C@@H](C)C(=O)O',        # Ibuprofen\n        'CC(=O)Oc1ccccc1C(=O)O',                   # Aspirin\n        'CC(=O)Nc1ccc(cc1)O',                      # Paracetamol\n        'Clc1ccc(cc1)C(c2ccccc2)N3CCCC3',         # Loratadine\n        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',           # Caffeine\n        'CC12CCC3C(C1CCC2O)CCC4=CC(=O)CCC34C',    # Testosterone\n        'C[C@]12CC[C@H]3[C@H]([C@@H]1CC[C@@H]2O)CCC4=CC(=O)CC[C@H]34', # Estradiol\n    ],\n    'IC50': [2.1, 5.4, 12.3, 0.8, 25.6, 3.2, 1.9],  # Inhibition concentration\n    'Solubility': [0.021, 0.3, 14.0, 0.004, 21.6, 0.024, 0.013],  # mg/mL\n    'Target': ['COX', 'COX', 'COX', 'H1R', 'PDE', 'AR', 'ER']\n}\n\ndrug_df = pd.DataFrame(drug_data)\nprint(\"Drug Discovery Dataset:\")\nprint(drug_df)\n\n# Apply targeted augmentation for each drug class\ntarget_groups = drug_df.groupby('Target')\n\naugmented_drugs = []\nfor target, group in target_groups:\n    print(f\"\\nAugmenting {target} inhibitors ({len(group)} compounds)...\")\n\n    # Adjust augmentation based on data availability\n    if len(group) &lt; 3:  # Small dataset - aggressive augmentation\n        aug_percentage = 1.0  # Double the data\n        methods = [\"mask\", \"delete\", \"fusion\", \"enumeration\"]\n    else:  # Larger dataset - conservative augmentation\n        aug_percentage = 0.5  # 50% more data\n        methods = [\"fusion\", \"enumeration\"]\n\n    aug_group = augment_dataset(\n        col_to_augment=\"SMILES\",\n        dataset=group,\n        augmentation_methods=methods,\n        mask_ratio=0.15,\n        delete_ratio=0.20,\n        augment_percentage=aug_percentage,\n        property_col=\"IC50\",\n        seed=42\n    )\n\n    augmented_drugs.append(aug_group)\n    print(f\"  {target}: {len(group)} -&gt; {len(aug_group)} compounds\")\n\n# Combine all augmented drug data\nfinal_drug_dataset = pd.concat(augmented_drugs, ignore_index=True)\n\nprint(f\"\\nFinal augmented drug dataset: {len(final_drug_dataset)} compounds\")\nprint(f\"Original: {len(drug_df)} -&gt; Augmented: {len(final_drug_dataset)}\")\nprint(f\"Expansion factor: {len(final_drug_dataset)/len(drug_df):.1f}x\")\n\n# Save for ML training\nfinal_drug_dataset.to_csv('augmented_drug_dataset.csv', index=False)\n</code></pre> <p>These examples demonstrate the versatility and practical applications of AugChem's SMILES augmentation capabilities for various molecular research scenarios, from basic data expansion to sophisticated drug discovery workflows.</p>"},{"location":"smiles_tutorial/","title":"SMILES Augmentation Tutorial","text":"<p>This tutorial demonstrates how to use AugChem's SMILES augmentation capabilities for molecular data enhancement.</p>"},{"location":"smiles_tutorial/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install augchem rdkit pandas\n</code></pre>"},{"location":"smiles_tutorial/#basic-setup","title":"Basic Setup","text":"<pre><code>from augchem import Augmentator\nimport pandas as pd\n\n# Initialize the augmentator with a seed for reproducibility\naugmentator = Augmentator(seed=42)\n</code></pre>"},{"location":"smiles_tutorial/#loading-and-preparing-smiles-data","title":"Loading and Preparing SMILES Data","text":"<pre><code>import pandas as pd\n\n# Create a sample dataset\ndata = {\n    'SMILES': [\n        'CC(=O)O',           # Acetic acid\n        'CCO',               # Ethanol  \n        'C1=CC=CC=C1',       # Benzene\n        'CC(C)O',            # Isopropanol\n        'C1=CC=C(C=C1)O'     # Phenol\n    ],\n    'Property_0': [0.45, 1.23, -0.87, 0.62, -0.34]\n}\n\ndf = pd.DataFrame(data)\ndf.to_csv('molecules.csv', index=False)\nprint(\"Sample dataset created!\")\n</code></pre>"},{"location":"smiles_tutorial/#individual-smiles-augmentation-methods","title":"Individual SMILES Augmentation Methods","text":"<pre><code>from augchem.modules.smiles.smiles_modules import (\n    mask, delete, swap, fusion, enumerateSmiles, tokenize\n)\n\noriginal_smiles = \"CC(=O)O\"  # Acetic acid\nprint(f\"Original SMILES: {original_smiles}\")\n\n# 1. Tokenization - understand SMILES structure\ntokens = tokenize(original_smiles)\nprint(f\"Tokens: {tokens}\")\n\n# 2. Masking - replace tokens with [M]\nmasked = mask(original_smiles, mask_ratio=0.3, seed=42)\nprint(f\"Masked: {masked}\")\n\n# 3. Deletion - remove random tokens\ndeleted = delete(original_smiles, delete_ratio=0.2, seed=42)\nprint(f\"Deleted: {deleted}\")\n\n# 4. Swapping - exchange atom positions\nswapped = swap(original_smiles, seed=42)\nprint(f\"Swapped: {swapped}\")\n\n# 5. Fusion - randomly apply mask/delete/swap\nfused = fusion(original_smiles, mask_ratio=0.1, delete_ratio=0.2, seed=42)\nprint(f\"Fused: {fused}\")\n\n# 6. Enumeration - generate non-canonical SMILES\nenumerated = enumerateSmiles(original_smiles)\nprint(f\"Enumerated: {enumerated}\")\n</code></pre>"},{"location":"smiles_tutorial/#dataset-level-smiles-augmentation","title":"Dataset-Level SMILES Augmentation","text":"<pre><code>from augchem.modules.smiles.smiles_modules import augment_dataset\n\n# Load your dataset\ndf = pd.read_csv('molecules.csv')\n\n# Apply augmentation using individual function\naugmented_df = augment_dataset(\n    col_to_augment=\"SMILES\",\n    dataset=df,\n    augmentation_methods=[\"mask\", \"delete\", \"fusion\", \"enumeration\"],\n    mask_ratio=0.1,\n    delete_ratio=0.3,\n    augment_percentage=0.4,  # 40% more molecules\n    property_col=\"Property_0\",\n    seed=42\n)\n\nprint(f\"Original: {len(df)} molecules\")\nprint(f\"Augmented: {len(augmented_df)} molecules\")\nprint(f\"New molecules: {len(augmented_df) - len(df)}\")\n</code></pre>"},{"location":"smiles_tutorial/#using-the-main-augmentator-class-recommended","title":"Using the Main Augmentator Class (Recommended)","text":"<pre><code># Using the main Augmentator class\naugmentator = Augmentator(seed=42)\n\n# Augment SMILES data\nresult = augmentator.SMILES.augment_data(\n    dataset=\"molecules.csv\",\n    augmentation_methods=[\"fusion\", \"enumeration\", \"mask\"],\n    mask_ratio=0.15,\n    delete_ratio=0.25,\n    augment_percentage=0.3,\n    col_to_augment=\"SMILES\",\n    property_col=\"Property_0\"\n)\n\nprint(f\"Augmentation complete! Dataset saved as 'Augmented_molecules.csv'\")\nprint(f\"Final dataset size: {len(result)} molecules\")\n</code></pre>"},{"location":"smiles_tutorial/#smiles-augmentation-methods-summary","title":"SMILES Augmentation Methods Summary","text":"Method Description Parameters Best For mask Replace tokens with '[M]' <code>mask_ratio</code> Language modeling delete Remove random tokens <code>delete_ratio</code> Robustness testing swap Exchange atom positions None Structural variation fusion Random method selection <code>mask_ratio</code>, <code>delete_ratio</code> Diverse augmentation enumeration Non-canonical SMILES None Canonical diversity"},{"location":"smiles_tutorial/#understanding-smiles-augmentation-results","title":"Understanding SMILES Augmentation Results","text":"<pre><code># Load and analyze augmentation results\nresult = pd.read_csv('Augmented_molecules.csv')\n\n# Check original vs augmented\noriginal_count = result['parent_idx'].isna().sum()\naugmented_count = len(result) - original_count\n\nprint(f\"Original molecules: {original_count}\")\nprint(f\"Augmented molecules: {augmented_count}\")\n\n# Look at augmentation examples\naugmented_only = result[result['parent_idx'].notna()]\nprint(\"\\nAugmentation examples:\")\nfor i in range(min(5, len(augmented_only))):\n    row = augmented_only.iloc[i]\n    parent_idx = int(row['parent_idx'])\n    original = result.iloc[parent_idx]['SMILES']\n    augmented = row['SMILES']\n    print(f\"Original: {original} \u2192 Augmented: {augmented}\")\n</code></pre>"},{"location":"smiles_tutorial/#smiles-quality-control","title":"SMILES Quality Control","text":"<pre><code>from rdkit import Chem\n\ndef validate_smiles(smiles_list):\n    \"\"\"Validate SMILES strings using RDKit\"\"\"\n    valid_count = 0\n    invalid_smiles = []\n\n    for smiles in smiles_list:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol is not None:\n            valid_count += 1\n        else:\n            invalid_smiles.append(smiles)\n\n    return valid_count, invalid_smiles\n\n# Validate augmented SMILES\nsmiles_list = result['SMILES'].tolist()\nvalid_count, invalid = validate_smiles(smiles_list)\n\nprint(f\"Valid SMILES: {valid_count}/{len(smiles_list)}\")\nprint(f\"Invalid SMILES: {len(invalid)}\")\nif invalid:\n    print(\"Examples of invalid SMILES:\", invalid[:3])\n</code></pre>"},{"location":"smiles_tutorial/#parameter-optimization","title":"Parameter Optimization","text":"<pre><code>def find_optimal_smiles_parameters():\n    \"\"\"Find optimal SMILES augmentation parameters\"\"\"\n\n    test_params = [\n        {'mask_ratio': 0.1, 'delete_ratio': 0.2, 'augment_percentage': 0.2},\n        {'mask_ratio': 0.15, 'delete_ratio': 0.3, 'augment_percentage': 0.3},\n        {'mask_ratio': 0.2, 'delete_ratio': 0.25, 'augment_percentage': 0.4},\n    ]\n\n    results = []\n\n    for params in test_params:\n        result = augmentator.SMILES.augment_data(\n            dataset=\"molecules.csv\",\n            **params,\n            augmentation_methods=[\"fusion\", \"mask\"]\n        )\n\n        # Calculate validity ratio\n        valid_count, invalid = validate_smiles(result['SMILES'].tolist())\n        valid_ratio = valid_count / len(result)\n\n        results.append({\n            **params,\n            'total_molecules': len(result),\n            'valid_ratio': valid_ratio\n        })\n\n    return pd.DataFrame(results)\n\n# Run optimization\noptimization_results = find_optimal_smiles_parameters()\nprint(optimization_results)\n</code></pre>"},{"location":"smiles_tutorial/#large-dataset-processing","title":"Large Dataset Processing","text":"<pre><code>def process_large_dataset(csv_path, chunk_size=1000):\n    \"\"\"Process large datasets in chunks\"\"\"\n\n    # Read dataset info\n    with open(csv_path) as f:\n        total_rows = sum(1 for line in f) - 1  # subtract header\n\n    augmented_chunks = []\n\n    for chunk_start in range(0, total_rows, chunk_size):\n        # Read chunk\n        chunk = pd.read_csv(csv_path, skiprows=range(1, chunk_start+1), nrows=chunk_size)\n\n        # Augment chunk\n        augmented_chunk = augmentator.SMILES.augment_data(\n            dataset=chunk,\n            augmentation_methods=[\"fusion\"],\n            augment_percentage=0.1\n        )\n\n        augmented_chunks.append(augmented_chunk)\n        print(f\"Processed chunk {chunk_start//chunk_size + 1}\")\n\n    # Combine results\n    final_result = pd.concat(augmented_chunks, ignore_index=True)\n    return final_result\n\n# Example usage for large datasets\n# large_result = process_large_dataset(\"large_molecules.csv\", chunk_size=500)\n</code></pre>"},{"location":"smiles_tutorial/#best-practices-for-smiles-augmentation","title":"Best Practices for SMILES Augmentation","text":""},{"location":"smiles_tutorial/#1-validation-first","title":"1. Validation First","text":"<p>Always validate SMILES strings before and after augmentation:</p> <pre><code># Validate input\nvalid_input = [s for s in original_smiles if validate_smiles([s])[0] &gt; 0]\nprint(f\"Valid input SMILES: {len(valid_input)}/{len(original_smiles)}\")\n</code></pre>"},{"location":"smiles_tutorial/#2-conservative-parameters","title":"2. Conservative Parameters","text":"<p>Start with low augmentation ratios:</p> <pre><code># Recommended starting parameters\nCONSERVATIVE_PARAMS = {\n    'mask_ratio': 0.1,\n    'delete_ratio': 0.2,\n    'augment_percentage': 0.2\n}\n</code></pre>"},{"location":"smiles_tutorial/#3-chemical-diversity-monitoring","title":"3. Chemical Diversity Monitoring","text":"<p>Check that augmentation preserves chemical diversity:</p> <pre><code>from rdkit import Chem\n\ndef check_diversity(smiles_list):\n    canonical_set = set()\n    for smiles in smiles_list:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol:\n            canonical = Chem.MolToSmiles(mol)\n            canonical_set.add(canonical)\n    return len(canonical_set)\n\norig_diversity = check_diversity(original_smiles)\naug_diversity = check_diversity(augmented_smiles)\nprint(f\"Diversity preserved: {aug_diversity &gt;= orig_diversity}\")\n</code></pre>"},{"location":"smiles_tutorial/#4-reproducible-augmentation","title":"4. Reproducible Augmentation","text":"<p>Always use seeds for reproducible results:</p> <pre><code># Reproducible augmentation\nEXPERIMENT_SEED = 42\naugmentator = Augmentator(seed=EXPERIMENT_SEED)\n\naugmented_1 = augmentator.SMILES.augment_data(\"molecules.csv\", seed=EXPERIMENT_SEED)\naugmented_2 = augmentator.SMILES.augment_data(\"molecules.csv\", seed=EXPERIMENT_SEED)\n# Results will be identical\n</code></pre>"},{"location":"smiles_tutorial/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"smiles_tutorial/#invalid-smiles-generation","title":"Invalid SMILES Generation","text":"<pre><code># Filter out invalid SMILES after augmentation\ndef filter_valid_smiles(df):\n    valid_mask = []\n    for smiles in df['SMILES']:\n        mol = Chem.MolFromSmiles(smiles)\n        valid_mask.append(mol is not None)\n\n    return df[valid_mask].reset_index(drop=True)\n\n# Apply filter\nclean_result = filter_valid_smiles(result)\nprint(f\"Filtered: {len(result)} \u2192 {len(clean_result)} valid molecules\")\n</code></pre>"},{"location":"smiles_tutorial/#property-column-handling","title":"Property Column Handling","text":"<pre><code># Ensure property columns are correctly preserved\nresult_with_properties = augmentator.SMILES.augment_data(\n    dataset=\"molecules.csv\",\n    property_col=\"Property_0\",  # Specify property column\n    augmentation_methods=[\"enumeration\"]  # Use safe methods\n)\n\n# Check property preservation\noriginal_props = df['Property_0'].tolist()\naugmented_props = result_with_properties['Property_0'].tolist()\nprint(f\"Properties preserved: {len(set(original_props))} unique values\")\n</code></pre>"},{"location":"smiles_tutorial/#integration-with-machine-learning","title":"Integration with Machine Learning","text":"<pre><code>from sklearn.model_selection import train_test_split\n\n# Prepare augmented dataset for ML\naugmented_smiles = result['SMILES'].tolist()\naugmented_labels = result['Property_0'].tolist()\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(\n    augmented_smiles, augmented_labels, \n    test_size=0.2, random_state=42\n)\n\nprint(f\"Training set: {len(X_train)} molecules\")\nprint(f\"Test set: {len(X_test)} molecules\")\n\n# Ready for molecular descriptors calculation and ML training\n</code></pre>"},{"location":"smiles_tutorial/#next-steps","title":"Next Steps","text":"<p>After completing this SMILES tutorial:</p> <ul> <li>\u2705 Understand all SMILES augmentation methods</li> <li>\u2705 Apply quality control and validation</li> <li>\u2705 Optimize parameters for your datasets</li> <li>\u2705 Handle large datasets efficiently</li> <li>\u2705 Integrate with ML pipelines</li> </ul>"},{"location":"smiles_tutorial/#see-also","title":"See Also","text":"<ul> <li>Graph Augmentation Tutorial - Learn graph-based augmentation</li> <li>SMILES Methods API - Complete method documentation</li> <li>Examples - Real-world applications</li> </ul>"},{"location":"tutorial/","title":"AugChem Tutorial","text":"<p>This comprehensive tutorial covers both SMILES and Graph augmentation capabilities in AugChem for molecular data enhancement.</p>"},{"location":"tutorial/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install augchem torch torch-geometric rdkit\n</code></pre>"},{"location":"reference/augchem/","title":"What is Augchem?","text":"<p>Augchem is a comprehensive toolbox for chemical data augmentation developed in partnership with CINE and FAPESP. It provides state-of-the-art techniques for augmenting molecular data across multiple representations.</p>"},{"location":"reference/augchem/#why-use-data-augmentation-for-chemical-data","title":"Why use data augmentation for chemical data?","text":"<p>Machine Learning (ML) is gaining prominence in the discovery of new materials, complementing traditional methods by analyzing large volumes of data and identifying patterns. The effectiveness of ML models depends on data quality, making data augmentation techniques essential to improve model accuracy in materials chemistry. However, there is a lack of studies integrating these techniques in this field. This toolbox aims to address this gap with easy-to-use Python libraries for chemical data augmentation.</p>"},{"location":"reference/augchem/#key-features","title":"Key Features","text":""},{"location":"reference/augchem/#smiles-augmentation","title":"\ud83d\udd24 SMILES Augmentation","text":"<ul> <li>Token Manipulation: Advanced parsing and modification of SMILES strings</li> <li>Masking Techniques: Replace molecular tokens with mask symbols for robust training</li> <li>Deletion Strategies: Remove random tokens to create structural variations</li> <li>Atom Swapping: Exchange atomic positions for diverse canonical representations</li> <li>Fusion Methods: Intelligently combine multiple augmentation techniques</li> <li>Enumeration: Generate non-canonical SMILES for increased diversity</li> <li>Chemical Validation: Built-in RDKit integration for molecular correctness</li> <li>Property Preservation: Maintain molecular properties during augmentation</li> </ul>"},{"location":"reference/augchem/#molecular-graph-augmentation","title":"\ud83d\udd17 Molecular Graph Augmentation","text":"<ul> <li>Edge Dropping: Systematic removal of molecular bonds for structural variation</li> <li>Node Dropping: Atomic removal while preserving molecular validity</li> <li>Feature Masking: Node feature perturbation for robust representation learning</li> <li>Edge Perturbation: Dynamic bond addition and removal for chemical space exploration</li> </ul>"},{"location":"reference/augchem/#integration-processing","title":"\u26a1 Integration &amp; Processing","text":"<ul> <li>PyTorch Geometric: Native support for modern graph neural network workflows</li> <li>Pandas Integration: Seamless DataFrame processing for molecular datasets</li> <li>Batch Operations: Efficient processing of large molecular databases</li> <li>RDKit Compatibility: Chemical validation and property calculation</li> <li>Reproducible Results: Seed-based random state management</li> </ul>"},{"location":"reference/augchem/#developer-experience","title":"\ud83d\udee0\ufe0f Developer Experience","text":"<ul> <li>Simple API: Intuitive interface through main Augmentator class</li> <li>Flexible Parameters: Customizable augmentation rates and methods</li> <li>Quality Control: Built-in validation and error handling</li> <li>Memory Efficient: Optimized tensor operations and data structures</li> <li>GPU Support: Acceleration for large-scale processing</li> </ul>"},{"location":"reference/augchem/#target-applications","title":"Target Applications","text":""},{"location":"reference/augchem/#smiles-based-applications","title":"\ud83d\udd24 SMILES-Based Applications","text":"<ul> <li>Language Models: Training chemical language models with augmented SMILES</li> <li>Property Prediction: Enhance datasets for molecular property regression</li> <li>Drug Discovery: Virtual compound generation and ADMET prediction</li> <li>Chemical Space Exploration: Systematic molecular diversity expansion</li> <li>Text-Based ML: Transformer and RNN training for chemical sequences</li> </ul>"},{"location":"reference/augchem/#graph-based-applications","title":"\ud83d\udd17 Graph-Based Applications","text":"<ul> <li>Graph Neural Networks: Training data enhancement for chemical GNNs</li> <li>Drug Discovery: Molecular property prediction with enhanced datasets</li> <li>Materials Science: Crystal structure and property augmentation</li> <li>Chemical Informatics: Robust molecular representation learning</li> <li>Structure-Activity Relationships: SAR modeling with diverse molecular graphs</li> </ul>"},{"location":"reference/augchem/#research-applications","title":"\ud83d\udd2c Research Applications","text":"<ul> <li>Cheminformatics Research: Systematic molecular dataset expansion</li> <li>ML Benchmarking: Standardized augmentation for fair model comparison</li> <li>Data Scarcity: Address limited training data in specialized chemical domains</li> <li>Robustness Testing: Evaluate model performance under molecular variations</li> </ul>"},{"location":"reference/graphs_methods/","title":"Graph Augmentation Methods","text":"<p>This section covers the advanced graph augmentation techniques available in Augchem, designed specifically for molecular graphs using PyTorch Geometric.</p>"},{"location":"reference/graphs_methods/#core-augmentation-functions","title":"Core Augmentation Functions","text":""},{"location":"reference/graphs_methods/#edge-dropping","title":"Edge Dropping","text":""},{"location":"reference/graphs_methods/#augchem.modules.graph.graphs_modules.edge_dropping","title":"<code>augchem.modules.graph.graphs_modules.edge_dropping(data: Data, drop_rate: float = 0.1) -&gt; Data</code>","text":"<p>Remove complete bidirectional edges from the graph (edge dropping)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>drop_rate</code> <code>float</code> <p>Bidirectional edge removal rate (0.0 to 1.0)</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Data</code> <p>Graph with edges removed</p> Source code in <code>augchem\\modules\\graph\\graphs_modules.py</code> <pre><code>def edge_dropping(data: Data, drop_rate: float = 0.1) -&gt; Data:\n    \"\"\"\n    Remove complete bidirectional edges from the graph (edge dropping)\n\n    Args:\n        data: torch_geometric graph\n        drop_rate: Bidirectional edge removal rate (0.0 to 1.0)\n\n    Returns:\n        Graph with edges removed\n    \"\"\"\n    if data.edge_index.size(1) == 0:\n        return data.clone()\n\n    edge_set = set()\n    for i in range(data.edge_index.size(1)):\n        src, dst = data.edge_index[0, i].item(), data.edge_index[1, i].item()\n        edge_pair = tuple(sorted([src, dst]))\n        edge_set.add(edge_pair)\n\n    unique_edges = list(edge_set)\n    num_unique_edges = len(unique_edges)\n\n    if num_unique_edges == 0:\n        return data.clone()\n\n    num_to_drop = max(1, int(num_unique_edges * drop_rate))\n\n    edges_to_drop = set(unique_edges[:num_to_drop])\n\n    keep_mask = []\n    for i in range(data.edge_index.size(1)):\n        src, dst = data.edge_index[0, i].item(), data.edge_index[1, i].item()\n        edge_pair = tuple(sorted([src, dst]))\n\n        keep_mask.append(edge_pair not in edges_to_drop)\n\n    keep_mask = torch.tensor(keep_mask, dtype=torch.bool)\n\n    new_edge_index = data.edge_index[:, keep_mask]\n\n    new_edge_attr = None\n    if hasattr(data, 'edge_attr') and data.edge_attr is not None and data.edge_attr.size(0) &gt; 0:\n        new_edge_attr = data.edge_attr[keep_mask]\n\n    new_data = Data(\n        x=data.x.clone(),\n        edge_index=new_edge_index,\n        edge_attr=new_edge_attr,\n        num_nodes=data.num_nodes\n    )\n\n    if hasattr(data, 'y') and data.y is not None:\n        new_data.y = data.y.clone()\n\n    return new_data\n</code></pre>"},{"location":"reference/graphs_methods/#node-dropping","title":"Node Dropping","text":""},{"location":"reference/graphs_methods/#augchem.modules.graph.graphs_modules.node_dropping","title":"<code>augchem.modules.graph.graphs_modules.node_dropping(data: Data, drop_rate: float = 0.1) -&gt; Data</code>","text":"<p>Remove nodes randomly from the graph (node dropping)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>drop_rate</code> <code>float</code> <p>Node removal rate (0.0 to 1.0)</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Data</code> <p>Graph with nodes removed</p> Source code in <code>augchem\\modules\\graph\\graphs_modules.py</code> <pre><code>def node_dropping(data: Data, drop_rate: float = 0.1) -&gt; Data:\n    \"\"\"\n    Remove nodes randomly from the graph (node dropping)\n\n    Args:\n        data: torch_geometric graph\n        drop_rate: Node removal rate (0.0 to 1.0)\n\n    Returns:\n        Graph with nodes removed\n    \"\"\"\n    if data.num_nodes &lt;= 1:\n        return data.clone()\n\n    num_nodes = data.num_nodes\n    num_to_drop = max(1, int(num_nodes * drop_rate))\n\n    nodes_to_keep = torch.randperm(num_nodes)[num_to_drop:]\n    nodes_to_keep = torch.sort(nodes_to_keep)[0]\n\n    node_mapping = torch.full((num_nodes,), -1, dtype=torch.long)\n    node_mapping[nodes_to_keep] = torch.arange(len(nodes_to_keep))\n\n    edge_mask = (node_mapping[data.edge_index[0]] &gt;= 0) &amp; (node_mapping[data.edge_index[1]] &gt;= 0)\n\n    new_edge_attr = None\n    if hasattr(data, 'edge_attr') and data.edge_attr is not None and data.edge_attr.size(0) &gt; 0:\n        if edge_mask.sum() &gt; 0:\n            new_edge_attr = data.edge_attr[edge_mask]\n        else:\n            new_edge_attr = torch.empty((0, data.edge_attr.size(1)), dtype=torch.float)\n\n    if edge_mask.sum() == 0:\n        new_edge_index = torch.empty((2, 0), dtype=torch.long)\n    else:\n        new_edge_index = node_mapping[data.edge_index[:, edge_mask]]\n\n    new_data = Data(\n        x=data.x[nodes_to_keep],\n        edge_index=new_edge_index,\n        edge_attr=new_edge_attr,\n        num_nodes=len(nodes_to_keep)\n    )\n\n    if hasattr(data, 'y') and data.y is not None:\n        new_data.y = data.y.clone()\n\n    return new_data\n</code></pre>"},{"location":"reference/graphs_methods/#feature-masking","title":"Feature Masking","text":""},{"location":"reference/graphs_methods/#augchem.modules.graph.graphs_modules.feature_masking","title":"<code>augchem.modules.graph.graphs_modules.feature_masking(data: Data, mask_rate: float = 0.1) -&gt; Data</code>","text":"<p>Mask node features randomly (feature masking)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>mask_rate</code> <code>float</code> <p>Feature masking rate (0.0 to 1.0)</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Data</code> <p>Graph with masked features</p> Source code in <code>augchem\\modules\\graph\\graphs_modules.py</code> <pre><code>def feature_masking(data: Data, mask_rate: float = 0.1) -&gt; Data:\n    \"\"\"\n    Mask node features randomly (feature masking)\n\n    Args:\n        data: torch_geometric graph\n        mask_rate: Feature masking rate (0.0 to 1.0)\n\n    Returns:\n        Graph with masked features\n    \"\"\"\n    new_data = data.clone()\n\n    mask_value = float('-inf')\n\n    if new_data.x.size(0) == 0:\n        return new_data\n\n    mask = torch.rand_like(new_data.x) &lt; mask_rate\n\n    new_data.x = new_data.x.clone()\n    new_data.x[mask] = mask_value\n\n    return new_data\n</code></pre>"},{"location":"reference/graphs_methods/#edge-perturbation","title":"Edge Perturbation","text":""},{"location":"reference/graphs_methods/#augchem.modules.graph.graphs_modules.edge_perturbation","title":"<code>augchem.modules.graph.graphs_modules.edge_perturbation(data: Data, add_rate: float = 0.05, remove_rate: float = 0.05) -&gt; Data</code>","text":"<p>Perturb the graph by adding and removing complete bidirectional edges (edge perturbation)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>add_rate</code> <code>float</code> <p>Bidirectional connection addition rate</p> <code>0.05</code> <code>remove_rate</code> <code>float</code> <p>Bidirectional connection removal rate</p> <code>0.05</code> <p>Returns:</p> Type Description <code>Data</code> <p>Perturbed graph</p> Source code in <code>augchem\\modules\\graph\\graphs_modules.py</code> <pre><code>def edge_perturbation(data: Data, add_rate: float = 0.05, remove_rate: float = 0.05) -&gt; Data:\n    \"\"\"\n    Perturb the graph by adding and removing complete bidirectional edges (edge perturbation)\n\n    Args:\n        data: torch_geometric graph\n        add_rate: Bidirectional connection addition rate\n        remove_rate: Bidirectional connection removal rate\n\n    Returns:\n        Perturbed graph\n    \"\"\"\n    perturbed_data = edge_dropping(data, remove_rate)\n\n    existing_bidirectional = set()\n    for i in range(perturbed_data.edge_index.size(1)):\n        src, dst = perturbed_data.edge_index[0, i].item(), perturbed_data.edge_index[1, i].item()\n        edge_pair = tuple(sorted([src, dst]))\n        existing_bidirectional.add(edge_pair)\n\n    num_nodes = data.num_nodes\n    max_possible_connections = num_nodes * (num_nodes - 1) // 2\n    current_connections = len(existing_bidirectional)\n    available_connections = max_possible_connections - current_connections\n\n    num_connections_to_add = int(available_connections * add_rate)\n\n    if num_connections_to_add &gt; 0:\n        all_possible_connections = set()\n        for i in range(num_nodes):\n            for j in range(i + 1, num_nodes):\n                all_possible_connections.add((i, j))\n\n        available_connections_list = list(all_possible_connections - existing_bidirectional)\n\n        if available_connections_list:\n            torch.manual_seed(42)\n            num_to_add = min(num_connections_to_add, len(available_connections_list))\n\n            indices = torch.randperm(len(available_connections_list))[:num_to_add]\n\n            new_bidirectional_edges = []\n            for idx in indices:\n                src, dst = available_connections_list[idx.item()]\n                new_bidirectional_edges.extend([[src, dst], [dst, src]])\n\n            if new_bidirectional_edges:\n                new_edge_index = torch.tensor(new_bidirectional_edges, dtype=torch.long).t()\n\n                perturbed_data.edge_index = torch.cat([perturbed_data.edge_index, new_edge_index], dim=1)\n\n                if hasattr(perturbed_data, 'edge_attr') and perturbed_data.edge_attr is not None and perturbed_data.edge_attr.size(0) &gt; 0:\n                    mean_edge_attr = perturbed_data.edge_attr.mean(dim=0, keepdim=True)\n                    new_edge_attrs = mean_edge_attr.repeat(new_edge_index.size(1), 1)\n                    perturbed_data.edge_attr = torch.cat([perturbed_data.edge_attr, new_edge_attrs], dim=0)\n\n    return perturbed_data\n</code></pre>"},{"location":"reference/graphs_methods/#dataset-augmentation","title":"Dataset Augmentation","text":""},{"location":"reference/graphs_methods/#augchem.modules.graph.graphs_modules.augment_dataset","title":"<code>augchem.modules.graph.graphs_modules.augment_dataset(graphs: List[Data], augmentation_methods: List[str], edge_drop_rate: float = 0.1, node_drop_rate: float = 0.1, feature_mask_rate: float = 0.1, edge_add_rate: float = 0.05, edge_remove_rate: float = 0.05, augment_percentage: float = 0.2, seed: int = 42) -&gt; List[Data]</code>","text":"<p>Apply data augmentation techniques to a list of graphs.</p> <p>Parameters:</p> Name Type Description Default <code>graphs</code> <code>List[Data]</code> <p>List of torch_geometric Data objects representing the graphs</p> required <code>augmentation_methods</code> <code>List[str]</code> <p>List of methods ['edge_drop', 'node_drop', 'feature_mask', 'edge_perturb']</p> required <code>edge_drop_rate</code> <code>float</code> <p>Rate of edge removal (0.0 to 1.0)</p> <code>0.1</code> <code>node_drop_rate</code> <code>float</code> <p>Rate of node removal (0.0 to 1.0)</p> <code>0.1</code> <code>feature_mask_rate</code> <code>float</code> <p>Rate of feature masking (0.0 to 1.0)</p> <code>0.1</code> <code>edge_add_rate</code> <code>float</code> <p>Rate of edge addition for perturbation</p> <code>0.05</code> <code>edge_remove_rate</code> <code>float</code> <p>Rate of edge removal for perturbation</p> <code>0.05</code> <code>augment_percentage</code> <code>float</code> <p>Size of the augmented dataset as a fraction of the original</p> <code>0.2</code> <code>seed</code> <code>int</code> <p>Seed for reproducibility</p> <code>42</code> <p>Returns:</p> Type Description <code>List[Data]</code> <p>List of augmented graphs (original + augmented)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If unknown augmentation methods are specified</p> Source code in <code>augchem\\modules\\graph\\graphs_modules.py</code> <pre><code>def augment_dataset(graphs: List[Data], augmentation_methods: List[str], \n                          edge_drop_rate: float = 0.1, node_drop_rate: float = 0.1, \n                          feature_mask_rate: float = 0.1, edge_add_rate: float = 0.05,\n                          edge_remove_rate: float = 0.05, augment_percentage: float = 0.2, \n                          seed: int = 42) -&gt; List[Data]:\n    \"\"\"\n    Apply data augmentation techniques to a list of graphs.\n\n    Args:\n        graphs: List of torch_geometric Data objects representing the graphs\n        augmentation_methods: List of methods ['edge_drop', 'node_drop', 'feature_mask', 'edge_perturb']\n        edge_drop_rate: Rate of edge removal (0.0 to 1.0)\n        node_drop_rate: Rate of node removal (0.0 to 1.0)\n        feature_mask_rate: Rate of feature masking (0.0 to 1.0)\n        edge_add_rate: Rate of edge addition for perturbation\n        edge_remove_rate: Rate of edge removal for perturbation\n        augment_percentage: Size of the augmented dataset as a fraction of the original\n        seed: Seed for reproducibility\n\n    Returns:\n        List of augmented graphs (original + augmented)\n\n    Raises:\n        ValueError: If unknown augmentation methods are specified\n    \"\"\"\n\n    if not graphs:\n        raise ValueError(\"List of graphs cannot be empty\")\n\n    valid_methods = {'edge_drop', 'node_drop', 'feature_mask', 'edge_perturb'}\n    for method in augmentation_methods:\n        if method not in valid_methods:\n            raise ValueError(f\"Unknown augmentation method: {method}. Valid methods: {valid_methods}\")\n\n\n    rng = np.random.RandomState(seed)\n\n    working_graphs = [graph.clone() for graph in graphs]\n\n    target_new_graphs = int(len(graphs) * augment_percentage)\n\n    augmented_graphs = []\n    augmented_count = 0\n\n\n    while augmented_count &lt; target_new_graphs:\n        try:\n            iteration_augmented: List[Data] = []\n\n            for method in augmentation_methods:\n                if method == \"edge_drop\":\n                    graph_to_augment = rng.randint(low=0, high=len(working_graphs))\n                    original_graph = working_graphs[graph_to_augment]\n\n                    augmented_graph = edge_dropping(\n                        original_graph, \n                        drop_rate=edge_drop_rate\n                    )\n                elif method == \"node_drop\":\n                    graph_to_augment = rng.randint(low=0, high=len(working_graphs))\n                    original_graph = working_graphs[graph_to_augment]\n\n                    augmented_graph = node_dropping(\n                        original_graph, \n                        drop_rate=node_drop_rate\n                    )\n                elif method == \"feature_mask\":\n                    graph_to_augment = rng.randint(low=0, high=len(working_graphs))\n                    original_graph = working_graphs[graph_to_augment]\n\n\n                    augmented_graph = feature_masking(\n                        original_graph, \n                        mask_rate=feature_mask_rate,\n                    )\n                elif method == \"edge_perturb\":\n                    graph_to_augment = rng.randint(low=0, high=len(working_graphs))\n                    original_graph = working_graphs[graph_to_augment]\n\n                    augmented_graph = edge_perturbation(\n                        original_graph, \n                        add_rate=edge_add_rate,\n                        remove_rate=edge_remove_rate\n                    )\n\n                augmented_graph.augmentation_method = method\n                augmented_graph.parent_idx = graph_to_augment\n\n                iteration_augmented.append(augmented_graph)\n\n            unique_augmented = iteration_augmented[:target_new_graphs - augmented_count]\n\n            for aug_graph in unique_augmented:\n                augmented_graphs.append(aug_graph)\n                augmented_count += 1\n\n                if augmented_count &gt;= target_new_graphs:\n                    break\n\n            if augmented_count &gt;= target_new_graphs:\n                break\n\n        except Exception as e:\n            print(f\"Error during augmentation: {e}\")\n            continue\n\n    all_graphs = working_graphs + augmented_graphs\n\n    print(f\"Augmenting finished: {len(working_graphs)} originals + {len(augmented_graphs)} augmented = {len(all_graphs)} total\")\n\n    return all_graphs\n</code></pre>"},{"location":"reference/graphs_methods/#usage-examples","title":"Usage Examples","text":""},{"location":"reference/graphs_methods/#basic-graph-augmentation","title":"Basic Graph Augmentation","text":"<pre><code>from augchem.modules.graph.graphs_modules import augment_dataset\nimport torch\nfrom torch_geometric.data import Data\n\n# Example: Create sample molecular graphs\ngraphs = [\n    Data(x=torch.randn(10, 5), edge_index=torch.randint(0, 10, (2, 20))),\n    Data(x=torch.randn(8, 5), edge_index=torch.randint(0, 8, (2, 16)))\n]\n\n# Apply multiple augmentation techniques\naugmented_graphs = augment_dataset(\n    graphs=graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask', 'edge_perturb'],\n    edge_drop_rate=0.1,\n    node_drop_rate=0.1, \n    feature_mask_rate=0.15,\n    edge_add_rate=0.05,\n    edge_remove_rate=0.05,\n    augment_percentage=0.3,\n    seed=42\n)\n\nprint(f\"Original: {len(graphs)} graphs\")\nprint(f\"Augmented: {len(augmented_graphs)} graphs\")\n</code></pre>"},{"location":"reference/graphs_methods/#individual-augmentation-techniques","title":"Individual Augmentation Techniques","text":"<pre><code>from augchem.modules.graph.graphs_modules import (\n    edge_dropping, node_dropping, feature_masking, edge_perturbation\n)\n\n# Apply individual techniques\ngraph = your_molecular_graph\n\n# Edge dropping - removes bidirectional connections\ngraph_edge_drop = edge_dropping(graph, drop_rate=0.1)\n\n# Node dropping - removes nodes and their connections\ngraph_node_drop = node_dropping(graph, drop_rate=0.1)\n\n# Feature masking - masks node features with -inf\ngraph_feature_mask = feature_masking(graph, mask_rate=0.15)\n\n# Edge perturbation - adds and removes edges\ngraph_perturbed = edge_perturbation(\n    graph, \n    add_rate=0.05, \n    remove_rate=0.05\n)\n</code></pre>"},{"location":"reference/graphs_methods/#working-with-pytorch-geometric-dataloaders","title":"Working with PyTorch Geometric DataLoaders","text":"<pre><code>from torch_geometric.loader import DataLoader\n\n# Create DataLoader with augmented graphs\ndataloader = DataLoader(\n    augmented_graphs,\n    batch_size=32,\n    shuffle=True\n)\n\n# Process batches\nfor batch in dataloader:\n    print(f\"Batch size: {batch.num_graphs}\")\n    print(f\"Total nodes: {batch.x.size(0)}\")\n    print(f\"Total edges: {batch.edge_index.size(1)}\")\n    break\n</code></pre>"},{"location":"reference/graphs_methods/#technical-notes","title":"Technical Notes","text":""},{"location":"reference/graphs_methods/#graph-integrity","title":"Graph Integrity","text":"<ul> <li>All augmentation functions preserve graph structure validity</li> <li>Node indices are properly remapped after node dropping</li> <li>Edge attributes are handled consistently across operations</li> </ul>"},{"location":"reference/graphs_methods/#bidirectional-edges","title":"Bidirectional Edges","text":"<ul> <li>Edge dropping and perturbation work with complete bidirectional edges</li> <li>This ensures molecular graph connectivity is maintained properly</li> <li>Single-direction edge operations would break chemical bond representation</li> </ul>"},{"location":"reference/graphs_methods/#feature-masking_1","title":"Feature Masking","text":"<ul> <li>Uses <code>-inf</code> as mask value for compatibility with attention mechanisms</li> <li>Masked features can be easily identified and handled in downstream models</li> <li>Preserves tensor shapes for batch processing</li> </ul>"},{"location":"reference/graphs_methods/#reproducibility","title":"Reproducibility","text":"<ul> <li>All augmentation functions support random seed control</li> <li>Deterministic results for the same input parameters and seed</li> <li>Essential for experimental reproducibility in research</li> </ul>"},{"location":"reference/graphs_methods/#memory-efficiency","title":"Memory Efficiency","text":"<ul> <li>All functions create cloned graphs to preserve originals</li> <li>Efficient tensor operations using PyTorch primitives</li> <li>Batch processing optimized for GPU acceleration</li> </ul>"},{"location":"reference/graphs_module/","title":"Graph Module","text":"<p>The Graph Module provides comprehensive tools for molecular graph data augmentation using PyTorch Geometric. This module includes advanced augmentation techniques specifically designed for chemical molecular graphs.</p>"},{"location":"reference/graphs_module/#module-overview","title":"Module Overview","text":""},{"location":"reference/graphs_module/#augchem.modules.graph","title":"<code>augchem.modules.graph</code>","text":""},{"location":"reference/graphs_module/#key-components","title":"Key Components","text":""},{"location":"reference/graphs_module/#graphs-modules","title":"Graphs Modules","text":"<p>The core functionality for graph augmentation techniques:</p>"},{"location":"reference/graphs_module/#augchem.modules.graph.graphs_modules","title":"<code>augchem.modules.graph.graphs_modules</code>","text":""},{"location":"reference/graphs_module/#augchem.modules.graph.graphs_modules.augment_dataset","title":"<code>augment_dataset(graphs: List[Data], augmentation_methods: List[str], edge_drop_rate: float = 0.1, node_drop_rate: float = 0.1, feature_mask_rate: float = 0.1, edge_add_rate: float = 0.05, edge_remove_rate: float = 0.05, augment_percentage: float = 0.2, seed: int = 42) -&gt; List[Data]</code>","text":"<p>Apply data augmentation techniques to a list of graphs.</p> <p>Parameters:</p> Name Type Description Default <code>graphs</code> <code>List[Data]</code> <p>List of torch_geometric Data objects representing the graphs</p> required <code>augmentation_methods</code> <code>List[str]</code> <p>List of methods ['edge_drop', 'node_drop', 'feature_mask', 'edge_perturb']</p> required <code>edge_drop_rate</code> <code>float</code> <p>Rate of edge removal (0.0 to 1.0)</p> <code>0.1</code> <code>node_drop_rate</code> <code>float</code> <p>Rate of node removal (0.0 to 1.0)</p> <code>0.1</code> <code>feature_mask_rate</code> <code>float</code> <p>Rate of feature masking (0.0 to 1.0)</p> <code>0.1</code> <code>edge_add_rate</code> <code>float</code> <p>Rate of edge addition for perturbation</p> <code>0.05</code> <code>edge_remove_rate</code> <code>float</code> <p>Rate of edge removal for perturbation</p> <code>0.05</code> <code>augment_percentage</code> <code>float</code> <p>Size of the augmented dataset as a fraction of the original</p> <code>0.2</code> <code>seed</code> <code>int</code> <p>Seed for reproducibility</p> <code>42</code> <p>Returns:</p> Type Description <code>List[Data]</code> <p>List of augmented graphs (original + augmented)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If unknown augmentation methods are specified</p>"},{"location":"reference/graphs_module/#augchem.modules.graph.graphs_modules.edge_dropping","title":"<code>edge_dropping(data: Data, drop_rate: float = 0.1) -&gt; Data</code>","text":"<p>Remove complete bidirectional edges from the graph (edge dropping)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>drop_rate</code> <code>float</code> <p>Bidirectional edge removal rate (0.0 to 1.0)</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Data</code> <p>Graph with edges removed</p>"},{"location":"reference/graphs_module/#augchem.modules.graph.graphs_modules.edge_perturbation","title":"<code>edge_perturbation(data: Data, add_rate: float = 0.05, remove_rate: float = 0.05) -&gt; Data</code>","text":"<p>Perturb the graph by adding and removing complete bidirectional edges (edge perturbation)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>add_rate</code> <code>float</code> <p>Bidirectional connection addition rate</p> <code>0.05</code> <code>remove_rate</code> <code>float</code> <p>Bidirectional connection removal rate</p> <code>0.05</code> <p>Returns:</p> Type Description <code>Data</code> <p>Perturbed graph</p>"},{"location":"reference/graphs_module/#augchem.modules.graph.graphs_modules.feature_masking","title":"<code>feature_masking(data: Data, mask_rate: float = 0.1) -&gt; Data</code>","text":"<p>Mask node features randomly (feature masking)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>mask_rate</code> <code>float</code> <p>Feature masking rate (0.0 to 1.0)</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Data</code> <p>Graph with masked features</p>"},{"location":"reference/graphs_module/#augchem.modules.graph.graphs_modules.node_dropping","title":"<code>node_dropping(data: Data, drop_rate: float = 0.1) -&gt; Data</code>","text":"<p>Remove nodes randomly from the graph (node dropping)</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Data</code> <p>torch_geometric graph</p> required <code>drop_rate</code> <code>float</code> <p>Node removal rate (0.0 to 1.0)</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Data</code> <p>Graph with nodes removed</p>"},{"location":"reference/graphs_module/#available-augmentation-techniques","title":"Available Augmentation Techniques","text":"Technique Description Use Case Edge Dropping Removes complete bidirectional edges Structural perturbation, robustness testing Node Dropping Removes nodes and associated edges Graph topology variation, missing data simulation Feature Masking Masks node features with -inf values Feature robustness, attention mechanism training Edge Perturbation Adds and removes edges simultaneously Chemical space exploration, bond variation"},{"location":"reference/graphs_module/#integration-features","title":"Integration Features","text":""},{"location":"reference/graphs_module/#pytorch-geometric-compatibility","title":"PyTorch Geometric Compatibility","text":"<ul> <li>Native support for <code>torch_geometric.data.Data</code> objects</li> <li>Seamless integration with PyTorch Geometric DataLoaders</li> <li>Optimized for graph neural network training pipelines</li> </ul>"},{"location":"reference/graphs_module/#batch-processing","title":"Batch Processing","text":"<ul> <li>Efficient processing of multiple graphs</li> <li>GPU acceleration support</li> <li>Memory-optimized operations</li> </ul>"},{"location":"reference/graphs_module/#quality-assurance","title":"Quality Assurance","text":"<ul> <li>Graph integrity validation</li> <li>Self-loop detection and removal</li> <li>Consistent edge attribute handling</li> </ul>"},{"location":"reference/graphs_module/#example-workflow","title":"Example Workflow","text":"<pre><code>from augchem.modules.graph.graphs_modules import augment_dataset\n\n# Define your molecular graphs\nmolecular_graphs = load_your_molecular_graphs()\n\n# Apply comprehensive augmentation\naugmented_dataset = augment_dataset(\n    graphs=molecular_graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask'],\n    augment_percentage=0.25,\n    seed=42\n)\n\n# Use in your machine learning pipeline\nfrom torch_geometric.loader import DataLoader\nloader = DataLoader(augmented_dataset, batch_size=32, shuffle=True)\n</code></pre>"},{"location":"reference/graphs_module/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Memory Usage: All operations create graph clones to preserve originals</li> <li>GPU Support: Full tensor operation compatibility with CUDA</li> <li>Scalability: Optimized for large molecular datasets</li> <li>Reproducibility: Deterministic results with seed control</li> </ul> <p>For detailed function documentation and examples, see the Graph Methods section.</p>"},{"location":"reference/loader/","title":"Data Loaders","text":"<p>This section covers the data loading utilities available in Augchem. These tools help you load and process molecular data from various formats for augmentation and analysis.</p>"},{"location":"reference/loader/#standard-loader","title":"Standard Loader","text":"<p>This class is a helper in case you don't have your own QM9 dataset loader. In case you have your own dataset loader, you can ignore these functions.</p> <p>It's important to note that these data augmentation methods aren't exclusive to the QM9 dataset, and can be used with any SMILES, graph or InChI data.</p>"},{"location":"reference/loader/#augchem.QM9Loader","title":"<code>augchem.QM9Loader(path: Path)</code>","text":"Source code in <code>augchem\\core.py</code> <pre><code>def __init__(self, path: Path):\n    self.path = path\n</code></pre>"},{"location":"reference/loader/#augchem.QM9Loader.load_qm9_dataset","title":"<code>load_qm9_dataset(directory_path, list_mols=[])</code>","text":"<p>Load the entire QM9 dataset from a directory containing .xyz files.</p> Source code in <code>augchem\\core.py</code> <pre><code>def load_qm9_dataset(self, directory_path, list_mols=[]):\n    \"\"\"Load the entire QM9 dataset from a directory containing .xyz files.\"\"\"\n    X = []\n    Y = []\n    S = []\n    SMILES1 = []\n    SMILES2 = []\n    INCHI1 = []\n    INCHI2 = []\n\n    for file_name in os.listdir(directory_path):\n        if file_name.endswith(\".xyz\"):\n            file_path = os.path.join(directory_path, file_name)\n            molecule_data = self.load_qm9_xyz(file_path)\n            if molecule_data['natoms'] in list_mols or len(list_mols)==0:\n                X.append([molecule_data['atoms'], molecule_data['coordinates']])\n                Y.append(molecule_data['properties'])\n                S.append(molecule_data['natoms'])\n                SMILES1.append(molecule_data['smiles_1'])\n                SMILES2.append(molecule_data['smiles_2'])\n                INCHI1.append(molecule_data['inchi_1'])\n                INCHI2.append(molecule_data['inchi_2'])\n\n    return X, Y, S, SMILES1, SMILES2, INCHI1, INCHI2\n</code></pre>"},{"location":"reference/loader/#augchem.QM9Loader.load_qm9_xyz","title":"<code>load_qm9_xyz(file_path)</code>","text":"<p>Load a single QM9.xyz file.</p> Source code in <code>augchem\\core.py</code> <pre><code>def load_qm9_xyz(self, file_path):\n    \"\"\"Load a single QM9.xyz file.\"\"\"\n    with open(file_path, 'r') as f:\n        # Number of atoms\n        natoms = int(f.readline())\n        # Properties are in the second line\n        properties = list(map(float, f.readline().split()[2:]))\n        # Read atomic coordinates and types\n        atoms = []\n        coordinates = []\n        smiles1 = ''\n        smiles2 = '' \n        inchi1 = ''\n        inchi2 = ''\n        # print(properties)\n        for num_line, line in enumerate(f):\n            # print(num_line, line)\n            if num_line &gt;= 0 and num_line &lt; natoms:\n                info = line.replace(\"*^\",\"e\").split()\n                atoms.append(info[0])\n                coordinates.append(list(map(float, info[1:-1])))\n            if num_line == natoms + 1:\n                smiles1, smiles2 = line.split()\n            if num_line == natoms + 2:\n                inchi1, inchi2 = line.split()\n\n    return {\n        \"natoms\": natoms,\n        \"atoms\": atoms,\n        \"coordinates\": np.array(coordinates),\n        \"smiles_1\": smiles1,\n        \"smiles_2\": smiles2,\n        \"inchi_1\": inchi1,\n        \"inchi_2\": inchi2,\n        \"properties\": properties\n    }\n</code></pre>"},{"location":"reference/loader/#pytorch-geometric-sdf-loader","title":"PyTorch Geometric SDF Loader","text":"<p>The <code>TorchGeometricSDFLoader</code> is a specialized loader for working with SDF (Structure-Data File) format using PyTorch Geometric. This loader is optimized for molecular graph processing and augmentation workflows.</p>"},{"location":"reference/loader/#key-features","title":"Key Features","text":"<ul> <li>Pure PyTorch Geometric: Uses only PyTorch Geometric primitives for optimal performance</li> <li>SDF Support: Direct loading from SDF files containing molecular structures</li> <li>Graph Conversion: Converts RDKit molecules to <code>torch_geometric.data.Data</code> objects</li> <li>Batch Processing: Integrated DataLoader creation for efficient training</li> <li>Analytics: Comprehensive graph statistics and visualization tools</li> <li>Self-loop Management: Automatic detection and removal for clean augmentation</li> </ul>"},{"location":"reference/loader/#example-usage","title":"Example Usage","text":"<pre><code># Initialize the loader\nloader = TorchGeometricSDFLoader(\n    sdf_path=\"path/to/molecules.sdf\",\n    transform=NormalizeFeatures()  # Optional transforms\n)\n\n# Load molecules from SDF\nmolecules = loader.load_sdf(max_molecules=1000)\n\n# Convert to PyTorch Geometric graphs\ngraphs = loader.convert_to_torch_geometric_graphs(\n    add_self_loops=False  # Important for augmentation techniques\n)\n\n# Create DataLoader for batch processing\ndataloader = loader.create_torch_geometric_dataloader(\n    batch_size=32, \n    shuffle=True\n)\n\n# Get comprehensive statistics\nstats = loader.get_torch_geometric_statistics()\nprint(f\"Total graphs: {stats['total_graphs']}\")\nprint(f\"Average nodes per graph: {stats['nodes_per_graph']['mean']:.2f}\")\n\n# Visualize a molecular graph\nloader.visualize_with_torch_geometric(idx=0)\n\n# Save processed graphs\nloader.save_torch_geometric_graphs(\"processed_graphs.pt\")\n</code></pre>"},{"location":"reference/loader/#graph-features","title":"Graph Features","text":""},{"location":"reference/loader/#node-features-9-dimensions","title":"Node Features (9 dimensions)","text":"<ol> <li>Atomic number</li> <li>Degree (number of bonds)</li> <li>Formal charge</li> <li>Hybridization type</li> <li>Aromaticity (boolean)</li> <li>Number of radical electrons</li> <li>Total number of hydrogens</li> <li>Ring membership (boolean)</li> <li>Atomic mass</li> </ol>"},{"location":"reference/loader/#edge-features-4-dimensions","title":"Edge Features (4 dimensions)","text":"<ol> <li>Bond type (single, double, triple, aromatic)</li> <li>Aromaticity (boolean)</li> <li>Ring membership (boolean)</li> <li>Conjugation (boolean)</li> </ol>"},{"location":"reference/loader/#augmentation-ready-processing","title":"Augmentation-Ready Processing","text":"<p>The loader is specifically designed to work seamlessly with the graph augmentation techniques:</p> <pre><code># Load and prepare graphs for augmentation\nloader = TorchGeometricSDFLoader(sdf_path, transform=None)\nmolecules = loader.load_sdf(max_molecules=500)\n\n# Convert without self-loops (optimal for edge dropping)\ngraphs = loader.convert_to_torch_geometric_graphs(add_self_loops=False)\n\n# Apply augmentation techniques\nfrom augchem.modules.graph.graphs_modules import augment_dataset\n\naugmented_graphs = augment_dataset(\n    graphs=graphs,\n    augmentation_methods=['edge_drop', 'node_drop', 'feature_mask'],\n    augment_percentage=0.3\n)\n</code></pre>"},{"location":"reference/loader/#advanced-analytics","title":"Advanced Analytics","text":"<pre><code># Check for self-loops before augmentation\nfrom your_utils import check_self_loops_in_graphs, remove_self_loops_from_graphs\n\n# Analyze self-loops\nself_loop_stats = check_self_loops_in_graphs(graphs)\nprint(f\"Graphs with self-loops: {self_loop_stats['graphs_with_self_loops']}\")\n\n# Clean graphs if needed\nif self_loop_stats['total_self_loops'] &gt; 0:\n    cleaned_graphs = remove_self_loops_from_graphs(graphs)\n    loader.graphs = cleaned_graphs  # Update loader with clean graphs\n\n# Comprehensive visualization\nplot_torch_geometric_statistics(cleaned_graphs)\n</code></pre>"},{"location":"reference/loader/#performance-tips","title":"Performance Tips","text":"<ol> <li>Memory Management: Load molecules in batches for large datasets</li> <li>Self-loop Removal: Always check and remove self-loops before augmentation</li> <li>Transform Selection: Use transforms without <code>AddSelfLoops</code> for augmentation workflows</li> <li>Batch Size: Optimize batch size based on your GPU memory</li> <li>Reproducibility: Set random seeds for consistent results</li> </ol>"},{"location":"reference/loader/#integration-with-machine-learning","title":"Integration with Machine Learning","text":"<pre><code># Create train/validation splits\nfrom sklearn.model_selection import train_test_split\n\ntrain_graphs, val_graphs = train_test_split(\n    augmented_graphs, \n    test_size=0.2, \n    random_state=42\n)\n\n# Create optimized DataLoaders\ntrain_loader = DataLoader(train_graphs, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_graphs, batch_size=64, shuffle=False)\n\n# Ready for GNN training!\nfor batch in train_loader:\n    # batch.x: node features\n    # batch.edge_index: edge connections\n    # batch.edge_attr: edge features\n    # batch.batch: graph assignment for nodes\n    pass\n</code></pre>"},{"location":"reference/smiles_methods/","title":"SMILES Methods","text":"<p>This section documents the SMILES strings manipulation and augmentation methods.</p>"},{"location":"reference/smiles_methods/#basic-functions","title":"Basic Functions","text":""},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.atom_positions","title":"<code>augchem.modules.smiles.smiles_modules.atom_positions(smiles: str) -&gt; Tuple[List[str], List[int]]</code>","text":"<p>Extracts individual characters from a SMILES string and identifies indices of atoms.</p> <p>This function tokenizes a SMILES string into individual characters and identifies positions of actual atoms by excluding special characters like brackets,  parentheses, bonds, digits, etc.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.atom_positions--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.atom_positions--returns","title":"Returns","text":"<p><code>Tuple[List[str]</code>, <code>List[int]]</code>     A tuple containing:     - List of individual characters from the SMILES string     - List of indices where non-special characters (atoms) are located</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.atom_positions--examples","title":"Examples","text":"<p>atom_positions(\"CC(=O)O\") = (['C', 'C', '(', '=', 'O', ')', 'O'], [0, 1, 4, 6])</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def atom_positions(smiles: str) -&gt; Tuple[List[str], List[int]]:\n    \"\"\"\n    Extracts individual characters from a SMILES string and identifies indices of atoms.\n\n    This function tokenizes a SMILES string into individual characters and identifies\n    positions of actual atoms by excluding special characters like brackets, \n    parentheses, bonds, digits, etc.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n\n    Returns\n    -------\n    `Tuple[List[str]`, `List[int]]`\n        A tuple containing:\n        - List of individual characters from the SMILES string\n        - List of indices where non-special characters (atoms) are located\n\n    Examples\n    --------\n    &gt;&gt;&gt; atom_positions(\"CC(=O)O\") = (['C', 'C', '(', '=', 'O', ')', 'O'], [0, 1, 4, 6])\n    \"\"\"\n    charset = set(['[', ']', '(', ')', '=', '#', '%', '.', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-', '0', '@'])\n\n    tokens = list(smiles)\n    non_charset_indices = []\n\n    for idx, token in enumerate(tokens):\n        if token not in charset:\n            non_charset_indices.append(idx)\n\n    return tokens, non_charset_indices\n</code></pre>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.tokenize","title":"<code>augchem.modules.smiles.smiles_modules.tokenize(smiles: str)</code>","text":"<p>Tokenizes a SMILES string using a regular expression pattern.</p> <p>Splits a SMILES string into chemically meaningful tokens according to a predefined regex pattern. This tokenization preserves atom types, bonds, stereochemistry, and other structural features.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.tokenize--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.tokenize--returns","title":"Returns","text":"<p><code>List[str]</code>     A list of chemical tokens extracted from the SMILES string</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.tokenize--examples","title":"Examples","text":"<p>tokenize(\"CC(=O)O\") = ['C', 'C', '(', '=', 'O', ')', 'O']</p> <p>tokenize(\"C1=CC=CC=C1\") = ['C', '1', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '1']</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def tokenize(smiles: str):\n    \"\"\"\n    Tokenizes a SMILES string using a regular expression pattern.\n\n    Splits a SMILES string into chemically meaningful tokens according to a\n    predefined regex pattern. This tokenization preserves atom types, bonds,\n    stereochemistry, and other structural features.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n\n    Returns\n    -------\n    `List[str]`\n        A list of chemical tokens extracted from the SMILES string\n\n    Examples\n    --------\n    &gt;&gt;&gt; tokenize(\"CC(=O)O\") = ['C', 'C', '(', '=', 'O', ')', 'O']\n\n    &gt;&gt;&gt; tokenize(\"C1=CC=CC=C1\") = ['C', '1', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '1']\n    \"\"\"\n\n    SMI_REGEX_PATTERN = r\"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|&gt;&gt;?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n    regex = re.compile(SMI_REGEX_PATTERN)\n\n    tokens = [token for token in regex.findall(smiles)]\n    return tokens\n</code></pre>"},{"location":"reference/smiles_methods/#augmentation-methods","title":"Augmentation Methods","text":""},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.enumerateSmiles","title":"<code>augchem.modules.smiles.smiles_modules.enumerateSmiles(smiles: str) -&gt; Optional[str]</code>","text":"<p>Generates a valid non-canonical SMILES representation of the input molecule.</p> <p>Creates an alternative, but chemically equivalent SMILES string by randomizing the atom ordering while preserving the molecular structure. Returns None if  the generation fails or produces an invalid SMILES.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.enumerateSmiles--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.enumerateSmiles--returns","title":"Returns","text":"<p><code>Optional[str]</code>     A new, valid SMILES string with randomized atom ordering, or None if generation fails</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.enumerateSmiles--raises","title":"Raises","text":"<p>ValueError     If the input SMILES string is invalid</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.enumerateSmiles--examples","title":"Examples","text":"<p>enumerateSmiles(\"CC(=O)O\") = 'OC(C)=O'</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def enumerateSmiles(smiles: str) -&gt; Optional[str]:\n    \"\"\"\n    Generates a valid non-canonical SMILES representation of the input molecule.\n\n    Creates an alternative, but chemically equivalent SMILES string by randomizing\n    the atom ordering while preserving the molecular structure. Returns None if \n    the generation fails or produces an invalid SMILES.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n\n    Returns\n    -------\n    `Optional[str]`\n        A new, valid SMILES string with randomized atom ordering, or None if generation fails\n\n    Raises\n    ------\n    ValueError\n        If the input SMILES string is invalid\n\n    Examples\n    --------\n    &gt;&gt;&gt; enumerateSmiles(\"CC(=O)O\") = 'OC(C)=O'\n    \"\"\"\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        raise ValueError(f\"Invalid SMILES string: {smiles}\")\n\n    random_smiles = Chem.MolToSmiles(mol, canonical=False, doRandom=True)\n    random_mol = Chem.MolFromSmiles(random_smiles)\n    if random_mol is None:\n        return None\n\n    # comparar inhchi a partir de objetos Mol, n\u00e3o de str\n    if Chem.MolToInchi(mol) == Chem.MolToInchi(random_mol):\n        return random_smiles\n\n    return None\n</code></pre>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.mask","title":"<code>augchem.modules.smiles.smiles_modules.mask(smiles: str, mask_ratio: float = 0.5, seed=45) -&gt; List[str]</code>","text":"<p>Replaces random tokens in a SMILES string with a masking token '[M]'.</p> <p>Tokenizes the SMILES string and randomly replaces a specified fraction of tokens with a mask token. Useful for creating partially obscured molecular representations for machine learning applications.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.mask--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule</p> <p><code>mask_ratio</code> : float, default=0.5     Fraction of tokens to replace with mask tokens (0.0 to 1.0)</p> <p><code>seed</code> : int or numpy.random.RandomState, default=45     Random seed or random number generator for reproducibility</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.mask--returns","title":"Returns","text":"<p><code>str</code>     SMILES string with selected tokens replaced by '[M]'</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.mask--examples","title":"Examples","text":"<p>mask(\"CC(=O)O\", mask_ratio=0.4, seed=42) = 'CM[M]'</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def mask(smiles: str, mask_ratio: float = 0.5, seed = 45) -&gt; List[str]:\n    \"\"\"\n    Replaces random tokens in a SMILES string with a masking token '[M]'.\n\n    Tokenizes the SMILES string and randomly replaces a specified fraction of tokens\n    with a mask token. Useful for creating partially obscured molecular representations\n    for machine learning applications.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n\n    `mask_ratio` : float, default=0.5\n        Fraction of tokens to replace with mask tokens (0.0 to 1.0)\n\n    `seed` : int or numpy.random.RandomState, default=45\n        Random seed or random number generator for reproducibility\n\n    Returns\n    -------\n    `str`\n        SMILES string with selected tokens replaced by '[M]'\n\n    Examples\n    --------\n    &gt;&gt;&gt; mask(\"CC(=O)O\", mask_ratio=0.4, seed=42) = 'C[M](=O)[M]'\n    \"\"\"\n    token = '[M]'\n\n    if isinstance(seed, int):\n        rng = np.random.RandomState(seed)\n    else:\n        rng = seed\n\n    sliced_smiles = tokenize(smiles)\n\n    masked = sliced_smiles.copy()\n\n    mask_indices = rng.choice(len(masked), int(len(masked) * mask_ratio), replace=False)\n\n    for idx in mask_indices:\n        masked[idx] = token\n\n    masked_string = ''.join(masked)\n\n    return masked_string\n</code></pre>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.delete","title":"<code>augchem.modules.smiles.smiles_modules.delete(smiles: str, delete_ratio: float = 0.3, seed=45) -&gt; List[str]</code>","text":"<p>Removes random tokens from a SMILES string.</p> <p>Tokenizes the SMILES string and randomly deletes a specified fraction of tokens. This creates an incomplete representation that can be used for data augmentation or model robustness testing.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.delete--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule</p> <p><code>delete_ratio</code> : float, default=0.3     Fraction of tokens to delete (0.0 to 1.0)</p> <p><code>seed</code> : int or numpy.random.RandomState, default=45     Random seed or random number generator for reproducibility</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.delete--returns","title":"Returns","text":"<p><code>str</code>     SMILES string with selected tokens removed</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.delete--examples","title":"Examples","text":"<p>delete(\"CC(=O)O\", delete_ratio=0.3, seed=42) = 'C(=O)O'</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def delete(smiles: str, delete_ratio: float = 0.3, seed = 45) -&gt; List[str]:\n    \"\"\"\n    Removes random tokens from a SMILES string.\n\n    Tokenizes the SMILES string and randomly deletes a specified fraction of tokens.\n    This creates an incomplete representation that can be used for data augmentation\n    or model robustness testing.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n\n    `delete_ratio` : float, default=0.3\n        Fraction of tokens to delete (0.0 to 1.0)\n\n    `seed` : int or numpy.random.RandomState, default=45\n        Random seed or random number generator for reproducibility\n\n    Returns\n    -------\n    `str`\n        SMILES string with selected tokens removed\n\n    Examples\n    --------\n    &gt;&gt;&gt; delete(\"CC(=O)O\", delete_ratio=0.3, seed=42) = 'C(=O)O'\n    \"\"\"\n\n    if isinstance(seed, int):\n        rng = np.random.RandomState(seed)\n    else:\n        rng = seed\n\n    sliced_smiles = tokenize(smiles)\n\n    deleted = sliced_smiles.copy()\n\n    delete_indices = rng.choice(len(deleted), int(len(deleted) * delete_ratio), replace=False)\n\n    for idx in delete_indices:\n        deleted[idx] = ''\n\n    deleted_string = ''.join(deleted)    \n\n    return deleted_string\n</code></pre>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.swap","title":"<code>augchem.modules.smiles.smiles_modules.swap(smiles: str, seed=45) -&gt; List[str]</code>","text":"<p>Exchanges two random atom tokens within a SMILES string.</p> <p>Identifies non-special character positions in the SMILES string and swaps two randomly selected atoms. This preserves the token count but alters the molecular structure.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.swap--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule <code>seed</code> : int or numpy.random.RandomState, default=45     Random seed or random number generator for reproducibility</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.swap--returns","title":"Returns","text":"<p>str     SMILES string with two atoms swapped</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.swap--examples","title":"Examples","text":"<p>swap(\"CC(=O)O\", seed=42) = 'OC(=O)C'</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def swap(smiles: str, seed = 45) -&gt; List[str]:\n    \"\"\"\n    Exchanges two random atom tokens within a SMILES string.\n\n    Identifies non-special character positions in the SMILES string and swaps\n    two randomly selected atoms. This preserves the token count but alters\n    the molecular structure.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n    `seed` : int or numpy.random.RandomState, default=45\n        Random seed or random number generator for reproducibility\n\n    Returns\n    -------\n    str\n        SMILES string with two atoms swapped\n\n    Examples\n    --------\n    &gt;&gt;&gt; swap(\"CC(=O)O\", seed=42) = 'OC(=O)C'\n    \"\"\"\n\n    if isinstance(seed, int):\n        rng = np.random.RandomState(seed)\n    else:\n        rng = seed\n\n    tokens, non_charset_indices = atom_positions(smiles)\n    swapped = tokens.copy()\n\n    idx1, idx2 = rng.choice(non_charset_indices, 2, replace=False)\n    swapped[idx1], swapped[idx2] = swapped[idx2], swapped[idx1]\n\n    swapped_string = ''.join(swapped)\n\n    return swapped_string\n</code></pre>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.fusion","title":"<code>augchem.modules.smiles.smiles_modules.fusion(smiles: str, mask_ratio: float = 0.05, delete_ratio: float = 0.3, seed=45) -&gt; List[str]</code>","text":"<p>Applies one randomly selected augmentation method to a SMILES string.</p> <p>Randomly chooses between masking, deletion, or swapping transformations and applies it to the input SMILES. This provides a diverse set of augmentation possibilities with a single function call.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.fusion--parameters","title":"Parameters","text":"<p><code>smiles</code> : str     A valid SMILES string representation of a molecule</p> <p><code>mask_ratio</code> : float, default=0.05     Fraction of tokens to mask if masking is selected (0.0 to 1.0)</p> <p><code>delete_ratio</code> : float, default=0.3     Fraction of tokens to delete if deletion is selected (0.0 to 1.0)</p> <p><code>seed</code> : int or numpy.random.RandomState, default=45     Random seed or random number generator for reproducibility</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.fusion--returns","title":"Returns","text":"<p><code>str</code>     Augmented SMILES string</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.fusion--raises","title":"Raises","text":"<p>ValueError     If input SMILES is empty or if augmentation fails</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.fusion--examples","title":"Examples","text":"<p>fusion(\"CC(=O)O\", seed=42) = 'CC(O)='</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def fusion(smiles: str, mask_ratio: float = 0.05, delete_ratio: float = 0.3, seed = 45) -&gt; List[str]:\n    \"\"\"\n    Applies one randomly selected augmentation method to a SMILES string.\n\n    Randomly chooses between masking, deletion, or swapping transformations and\n    applies it to the input SMILES. This provides a diverse set of augmentation\n    possibilities with a single function call.\n\n    Parameters\n    ----------\n    `smiles` : str\n        A valid SMILES string representation of a molecule\n\n    `mask_ratio` : float, default=0.05\n        Fraction of tokens to mask if masking is selected (0.0 to 1.0)\n\n    `delete_ratio` : float, default=0.3\n        Fraction of tokens to delete if deletion is selected (0.0 to 1.0)\n\n    `seed` : int or numpy.random.RandomState, default=45\n        Random seed or random number generator for reproducibility\n\n    Returns\n    -------\n    `str`\n        Augmented SMILES string\n\n    Raises\n    ------\n    ValueError\n        If input SMILES is empty or if augmentation fails\n\n    Examples\n    --------\n    &gt;&gt;&gt; fusion(\"CC(=O)O\", seed=42) = 'CC(O)='\n    \"\"\"\n\n    if hasattr(seed, 'choice') and callable(seed.choice):\n        rng = seed\n    else:\n        rng = np.random.RandomState(seed)\n\n    if not smiles:\n        raise ValueError(\"Empty SMILES string isn't valid.\")\n\n    chosen = rng.choice(3, 1)[0]\n\n    try:\n        if chosen == 0:\n            augmented = mask(smiles, mask_ratio=mask_ratio, seed=rng)\n        elif chosen == 1:\n            augmented = delete(smiles, delete_ratio=delete_ratio, seed=rng)\n        else:\n            augmented = swap(smiles, seed=rng)\n\n    except Exception as e:\n        print(f\"Error during augmentation of {smiles}: {str(e)}\")\n        raise ValueError(e) \n\n    return augmented\n</code></pre>"},{"location":"reference/smiles_methods/#dataset-augmentation","title":"Dataset Augmentation","text":""},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.augment_dataset","title":"<code>augchem.modules.smiles.smiles_modules.augment_dataset(col_to_augment: str, dataset: pd.DataFrame, augmentation_methods: List[str], mask_ratio: float = 0.1, property_col: str = None, delete_ratio: float = 0.3, augment_percentage: float = 0.2, seed: int = 42)</code>","text":"<p>Applies selected augmentation methods to SMILES strings in a dataset.</p> <p>Generates augmented variants of molecular SMILES strings using specified methods and adds them to the dataset. Tracks relationships between original and augmented molecules using parent indices.</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.augment_dataset--parameters","title":"Parameters","text":"<p><code>col_to_augment</code> : str     Column name containing SMILES strings to augment</p> <p><code>dataset</code> : pd.DataFrame     DataFrame containing molecular data with SMILES strings</p> <p><code>augmentation_methods</code> : List[str]     List of methods to apply. Valid options: \"mask\", \"delete\", \"swap\", \"fusion\", \"enumeration\"</p> <p><code>mask_ratio</code> : float, default=0.1     Fraction of tokens to mask when using mask augmentation</p> <p><code>property_col</code> : str, optional     Column name containing property values to preserve in augmented data</p> <p><code>delete_ratio</code> : float, default=0.3     Fraction of tokens to delete when using delete augmentation</p> <p><code>augment_percentage</code> : float, default=0.2     Target size of augmented dataset as a fraction of original dataset size</p> <p><code>seed</code> : int, default=42     Random seed for reproducibility</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.augment_dataset--returns","title":"Returns","text":"<p><code>pd.DataFrame</code>     Original dataset with augmented molecules appended, including a 'parent_idx'     column that references original molecule indices</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.augment_dataset--raises","title":"Raises","text":"<p>ValueError     If input data is not in SMILES format or an unknown augmentation method is specified</p>"},{"location":"reference/smiles_methods/#augchem.modules.smiles.smiles_modules.augment_dataset--notes","title":"Notes","text":"<p>Property columns with names starting with \"Property_\" will be set to \"-\" in augmented rows.</p> Source code in <code>augchem\\modules\\smiles\\smiles_modules.py</code> <pre><code>def augment_dataset(col_to_augment: str, dataset: pd.DataFrame, augmentation_methods: List[str], mask_ratio: float = 0.1, property_col: str = None, delete_ratio: float = 0.3,\n                     augment_percentage: float = 0.2, seed: int = 42):\n    \"\"\"\n    Applies selected augmentation methods to SMILES strings in a dataset.\n\n    Generates augmented variants of molecular SMILES strings using specified methods\n    and adds them to the dataset. Tracks relationships between original and augmented\n    molecules using parent indices.\n\n    Parameters\n    ----------\n    `col_to_augment` : str\n        Column name containing SMILES strings to augment\n\n    `dataset` : pd.DataFrame\n        DataFrame containing molecular data with SMILES strings\n\n    `augmentation_methods` : List[str]\n        List of methods to apply. Valid options: \"mask\", \"delete\", \"swap\", \"fusion\", \"enumeration\"\n\n    `mask_ratio` : float, default=0.1\n        Fraction of tokens to mask when using mask augmentation\n\n    `property_col` : str, optional\n        Column name containing property values to preserve in augmented data\n\n    `delete_ratio` : float, default=0.3\n        Fraction of tokens to delete when using delete augmentation\n\n    `augment_percentage` : float, default=0.2\n        Target size of augmented dataset as a fraction of original dataset size\n\n    `seed` : int, default=42\n        Random seed for reproducibility\n\n    Returns\n    -------\n    `pd.DataFrame`\n        Original dataset with augmented molecules appended, including a 'parent_idx'\n        column that references original molecule indices\n\n    Raises\n    ------\n    ValueError\n        If input data is not in SMILES format or an unknown augmentation method is specified\n\n    Notes\n    -----\n    Property columns with names starting with \"Property_\" will be set to \"-\" in augmented rows.\n    \"\"\"\n\n    try:\n        mol = Chem.MolFromSmiles(dataset[col_to_augment][0])\n    except Exception as e:\n        raise ValueError(\"Input appears to be in the wrong format. This function only works with SMILES format.\")\n\n    rng = np.random.RandomState(seed)\n\n    if property_col:\n        working_copy = dataset[[col_to_augment, property_col]].copy()\n    else:\n        working_copy = dataset[[col_to_augment]].copy()\n\n    target_new_rows = int(len(dataset) * augment_percentage)\n\n    new_rows = []\n    augmented_count = 0\n\n    while augmented_count &lt; target_new_rows:\n        try:\n            augmented_smiles: List[str] = []\n            for method in augmentation_methods:\n                if method == \"mask\":\n                    row_to_augment = rng.randint(low=0, high=(len(dataset)-1))\n                    original_idx = working_copy.index[row_to_augment]\n                    row = working_copy.iloc[row_to_augment].copy()\n\n                    smiles = row[col_to_augment]\n                    # print(f\"Augmenting {smiles} with {method} method.\")\n\n                    augmented_smiles.append(mask(\n                        smiles,\n                        mask_ratio=mask_ratio,\n                        seed=rng\n                    ))\n                elif method == \"delete\":\n                    row_to_augment = rng.randint(low=0, high=(len(dataset)-1))\n                    original_idx = working_copy.index[row_to_augment]\n                    row = working_copy.iloc[row_to_augment].copy()\n\n                    smiles = row[col_to_augment]\n                    # print(f\"Augmenting {smiles} with {method} method.\")\n\n                    augmented_smiles.append(delete(\n                        smiles,\n                        delete_ratio=delete_ratio,\n                        seed=rng\n                    ))\n                elif method == \"swap\":\n                    row_to_augment = rng.randint(low=0, high=(len(dataset)-1))\n                    original_idx = working_copy.index[row_to_augment]\n                    row = working_copy.iloc[row_to_augment].copy()\n\n                    smiles = row[col_to_augment]\n                    # print(f\"Augmenting {smiles} with {method} method.\")\n\n                    augmented_smiles.append(swap(\n                        smiles,\n                        seed=rng\n                    ))\n                elif method == \"fusion\":\n                    row_to_augment = rng.randint(low=0, high=(len(dataset)-1))\n                    original_idx = working_copy.index[row_to_augment]\n                    row = working_copy.iloc[row_to_augment].copy()\n\n                    smiles = row[col_to_augment]\n                    # print(f\"Augmenting {smiles} with {method} method.\")\n\n                    augmented_smiles.append(fusion(\n                        smiles,\n                        mask_ratio=mask_ratio,\n                        delete_ratio=delete_ratio,\n                        seed=rng\n                    ))\n                elif method == \"enumeration\":\n                    row_to_augment = rng.randint(low=0, high=(len(dataset)-1))\n                    original_idx = working_copy.index[row_to_augment]\n                    row = working_copy.iloc[row_to_augment].copy()\n\n                    smiles = row[col_to_augment]\n                    # print(f\"Augmenting {smiles} with {method} method.\")\n\n                    augmented_smiles.append(enumerateSmiles(\n                        smiles\n                    ))\n                else:\n                    raise ValueError(f\"Unknown augmentation method: {method}\")\n\n            augmented_smiles = list(dict.fromkeys(augmented_smiles))\n            augmented_smiles = augmented_smiles[: target_new_rows - augmented_count]\n\n            for aug_smiles in augmented_smiles:\n                new_row = row.copy()\n                new_row[col_to_augment] = aug_smiles\n\n                for prop_col in [c for c in new_row.index if c.startswith(\"Property_\")]:\n                    new_row[prop_col] = \"-\"\n                new_row[\"parent_idx\"] = original_idx\n                new_rows.append(new_row)\n                augmented_count += 1\n                if augmented_count &gt;= target_new_rows:\n                    break\n\n            if augmented_count &gt;= target_new_rows:\n                break\n\n        except Exception:\n            continue\n\n    filtered_df = dataset[[col_to_augment, property_col]].copy()\n\n    if new_rows:\n        new_data = pd.DataFrame(new_rows)\n        augmented_df = pd.concat([filtered_df, new_data], ignore_index=True)\n        augmented_df = augmented_df.fillna(\"-1\")\n\n    return augmented_df\n</code></pre>"},{"location":"reference/smiles_module/","title":"SMILES Module","text":"<p>This module provides methods for augmenting molecular data in SMILES format.</p>"},{"location":"reference/smiles_module/#augchem.Augmentator.SMILESModule","title":"<code>augchem.Augmentator.SMILESModule(parent)</code>","text":"<p>Module for augmenting molecular data in SMILES format.</p> <p>Provides methods for generating augmented SMILES representations using various techniques including masking, deletion, swapping, fusion, and enumeration.</p> Source code in <code>augchem\\core.py</code> <pre><code>def __init__(self, parent):\n    self.parent = parent\n</code></pre>"},{"location":"reference/smiles_module/#augchem.Augmentator.SMILESModule.augment_data","title":"<code>augment_data(dataset: Path, mask_ratio: float = 0.1, delete_ratio: float = 0.3, seed: int = 42, augment_percentage: float = 0.2, augmentation_methods: List[str] = ['fusion', 'enumerate'], col_to_augment: str = 'SMILES', property_col: str = None) -&gt; pd.DataFrame</code>","text":"<p>Augment molecular SMILES data from a CSV file.</p> <p>Reads SMILES strings from a CSV file, applies specified augmentation methods, and returns the augmented dataset. Also saves the augmented dataset to a new CSV file.</p>"},{"location":"reference/smiles_module/#augchem.Augmentator.SMILESModule.augment_data--parameters","title":"Parameters","text":"<p><code>dataset</code> : Path     Path to the CSV file containing SMILES data to augment</p> <p><code>mask_ratio</code> : float, default=0.1     Fraction of tokens to mask when using masking-based augmentation methods</p> <p><code>delete_ratio</code> : float, default=0.3     Fraction of tokens to delete when using deletion-based augmentation methods</p> <p><code>seed</code> : int, default=42     Random seed for reproducible augmentation</p> <p><code>augment_percentage</code> : float, default=0.2     Target size of augmented dataset as a fraction of original dataset size</p> <p><code>augmentation_methods</code> : List[str], default=[\"fusion\", \"enumerate\"]     List of augmentation methods to apply. Valid options include:      \"mask\", \"delete\", \"swap\", \"fusion\", \"enumeration\"</p> <p><code>col_to_augment</code> : str, default='SMILES'     Column name in the CSV file containing SMILES strings to augment</p> <p><code>property_col</code> : str, optional     Column name containing property values to preserve in augmented data</p>"},{"location":"reference/smiles_module/#augchem.Augmentator.SMILESModule.augment_data--returns","title":"Returns","text":"<p><code>pd.DataFrame</code>     DataFrame containing both original and augmented molecules, with a 'parent_idx'     column linking augmented molecules to their source molecules</p>"},{"location":"reference/smiles_module/#augchem.Augmentator.SMILESModule.augment_data--notes","title":"Notes","text":"<p>The augmented dataset is automatically saved to \"Augmented_QM9.csv\" in the current working directory.</p> Source code in <code>augchem\\core.py</code> <pre><code>def augment_data(self, dataset: Path, mask_ratio: float = 0.1, delete_ratio: float = 0.3, seed: int = 42, \n                    augment_percentage: float = 0.2, augmentation_methods: List[str] = [\"fusion\", \"enumerate\"], col_to_augment: str = 'SMILES',\n                    property_col: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Augment molecular SMILES data from a CSV file.\n\n    Reads SMILES strings from a CSV file, applies specified augmentation methods,\n    and returns the augmented dataset. Also saves the augmented dataset to a new CSV file.\n\n    Parameters\n    ----------\n    `dataset` : Path\n        Path to the CSV file containing SMILES data to augment\n\n    `mask_ratio` : float, default=0.1\n        Fraction of tokens to mask when using masking-based augmentation methods\n\n    `delete_ratio` : float, default=0.3\n        Fraction of tokens to delete when using deletion-based augmentation methods\n\n    `seed` : int, default=42\n        Random seed for reproducible augmentation\n\n    `augment_percentage` : float, default=0.2\n        Target size of augmented dataset as a fraction of original dataset size\n\n    `augmentation_methods` : List[str], default=[\"fusion\", \"enumerate\"]\n        List of augmentation methods to apply. Valid options include: \n        \"mask\", \"delete\", \"swap\", \"fusion\", \"enumeration\"\n\n    `col_to_augment` : str, default='SMILES'\n        Column name in the CSV file containing SMILES strings to augment\n\n    `property_col` : str, optional\n        Column name containing property values to preserve in augmented data\n\n    Returns\n    -------\n    `pd.DataFrame`\n        DataFrame containing both original and augmented molecules, with a 'parent_idx'\n        column linking augmented molecules to their source molecules\n\n    Notes\n    -----\n    The augmented dataset is automatically saved to \"Augmented_QM9.csv\" in the\n    current working directory.\n    \"\"\"\n    df = pd.read_csv(dataset)\n    new_df = augment_dataset(dataset=df, augmentation_methods=augmentation_methods, mask_ratio=mask_ratio, delete_ratio=delete_ratio, \n                               col_to_augment=col_to_augment, augment_percentage=augment_percentage, seed=seed,\n                               property_col=property_col)\n\n\n    new_df = new_df.drop_duplicates()\n    new_df.to_csv(f\"Augmented_{dataset}\", index=True, float_format='%.8e')\n\n    new_data = len(new_df) - len(df)\n    print(f\"Generated new {new_data} SMILES\")\n\n    return new_df\n</code></pre>"}]}